参考资料：
https://www.jianshu.com/p/7767d5d8e648

https://labuladong.gitbook.io/algo/labuladong-he-ta-de-peng-you-men/jin-40-zhang-tu-jie-bei-wen-qian-bai-bian-de-tcp-san-ci-wo-shou-he-si-ci-hui-shou-mian-shi-ti

https://blog.csdn.net/guizaijianchic/article/details/77961418

https://juejin.im/post/5e11d2b36fb9a0481d28b4aa

# 计算机网络体系结构

**计算机网络体系结构分为3种：OSI体系结构、TCP/IP体系结构、五层体系结构**

- OSI体系结构：概念清楚且理念完整，但复杂且不实用
- TCP/IP体系结构：含了一系列构成互联网基础的网络协议，是Internet的核心协议，被广泛应用于局域网和广域网
- 五层体系结构：融合了OSI与TCP/IP的体系结构，目的是为了学习与讲解计算机原理

<div align=center><img src=Pictures/计算机网络体系结构.webp></div>

其中TCP/IP体系结构较为广泛：

<div align=center><img src=Pictures/TCP_IP体系结构.webp></div>

OSI的体系结构详细介绍：**交换机主要工作在数据链路层（第二层）；路由器工作在网络层（第三层）**

<div align=center><img src=Pictures\OSI的体系结构.png></div>

<div align=center><img src=Pictures\协议.jpg></div>


# HTTP与HTTPS

HTTP协议全称`Hyper Text Transfer Protocol`超文本传输协议，位于TCP/IP四层模型当中的应用层。

应用层(HTTP/FTP)；传输层(TCP/UDP)；网络层(IP/ARP)。



## 什么是HTTP

<div align=center><img src=Pictures/HTTP.jpg></div>

**超文本传输协议**(HyperText Transfer Protocol)，是一个基于**请求与响应**，**无状态**的**应用层**协议，**采用TCP作为运输层协议，因此传输可靠性高**，互联网上应用最为广泛的一种网络协议。设计HTTP的初衷是为了**提供一种发布和接收HTML页面的方法**。

### 常用的HTTP方法

- GET：用于**请求访问已经被URI**（Uniform Resource Identifier——统一资源标识符——表示的是web上每一种**可用的资源**，如 HTML文档、图像、视频片段、程序等）**识别的资源**，可以通过URL（Uniform Resource Locator——统一资源定位符——**指定文档所在地址、路径**）**传参给服务器**；
- POST：用于**传输信息给服务器**，主要功能与GET方法类似，但一般推荐使用POST方式。
- PUT：传输文件，报文主体中包含文件内容，保存到对应URI位置。
- HEAD：获得报文首部，与GET方法类似，只是不返回报文主体，一般用于验证URI是否有效。
- DELETE：删除文件，与PUT方法相反，删除对应URI位置的文件。
- OPTIONS：查询相应URI支持的HTTP方法。

#### GET方法与POST方法的区别

<div align=center><img src=Pictures\GET_POST区别.webp></div>

GET和POST本质都是HTTP请求，只不过对它们的作用做了界定和适配，并且让他们适应各自的场景。

- 本质区别：GET只是**一次HTTP请求**，POST先发请求头再发请求体，实际上是**两次请求**。

- 从功能上讲，GET一般用来<font color=red>从服务器上获取资源</font>，POST一般用来<font color=red>发送数据，更新服务器上的资源</font>；

- 从REST服务角度上说，GET是幂等的，即**读取同一个资源，总是得到相同的数据**；而POST不是幂等的，因为每次请求对资源的改变并不是相同的；进一步地，GET不会改变服务器上的资源，而POST会对服务器资源进行改变；

- 从请求参数形式上看
  - GET请求的数据会附在URL之后，如`http://127.0.0.1/Test/login.action?name=admin&password=admin`，即<font color=red>将请求数据放置在HTTP报文的请求头中</font>，以?分割URL和传输数据，参数之间以&相连。特别地，如果数据是英文字母/数字，原样发送；否则，会将其编码为`application/x-www-form-urlencoded MIME`字符串(如果是空格，转换为+，如果是**中文/其他字符**，则直接把字符串用BASE64加密，得出如：`%E4%BD%A0%E5%A5%BD`，其中`%XX`中的XX为该符号以16进制表示的ASCII)；
  - 而POST请求会把提交的数据则放置在是HTTP请求报文的<font color=red>请求体中</font>。

- 就安全性而言
  - <font color=red>POST的安全性要比GET的安全性高</font>，因为GET请求提交的数据将明文出现在URL上；
  - 而且POST请求参数则**被包装到请求体中**，相对更安全；

- 从请求的大小看
  - GET请求的长度**受限于浏览器或服务器对URL长度的限制**，允许发送的数据量比较小；
  - 而**POST请求则是没有大小限制的**。

- GET方式只能支持ASCII字符，向服务器传的中文字符可能会乱码。POST支持标准字符集，可以正确传递中文字符。



HTTP协议采用**请求/响应**的工作方式：

<div align=center><img src=Pictures\HTTP工作方式.webp></div>

### HTTP请求报文

<div align=center><img src=Pictures\HTTP请求报文1.webp></div>

HTTP的请求报文由`请求行、请求头和请求体`组成：

<div align=center><img src=Pictures\HTTP请求报文.webp></div>
<div align=center><img src=Pictures\HTTP请求报文.png></div>

#### 请求行

- 作用
  声明`请求方法、主机域名、资源路径和协议版本`
- 结构
  请求行的组成：`请求方法 + 请求路径 + 协议版本`

注：空格不能省

<div align=center><img src=Pictures\HTTP请求行组成.webp></div>

假设：请求报文采用GET方法，URL地址为`http://www.tsinghua.edu.cn/chn/yxsz/index.htm`且使用HTTP1.1版本，则请求行是：`GET /chn/yxsz/index.htm HTTP/1.1`。

#### 请求头

- 作用：声明客户端、服务器/报文的部分信息
- 使用方式：采用`header(字段名)：value(值)`的方式

<div align=center><img src=Pictures\常见请求Header.webp width=80%></div>

举例：(URL地址：`http://www.tsinghua.edu.cn/chn/yxsz/index.htm`）
Host：www.tsinghua.edu.cn (表示主机域名），客户端发送请求时，用来指定服务器的域名。
User - Agent：Mozilla/5.0 (表示用户代理是使用Netscape浏览器）

**HTTP常见字段**

Host字段：客户端发送请求时，用来指定服务器的域名。有了Host字段，就可以将请求发往「同一台」服务器上的不同网站。

<div align=center><img src=Pictures\HTTP字段.jpg width=70%></div>

Content-Length字段：服务器在返回数据时，会有Content-Length字段，表明本次回应的数据长度。

Connection字段：Connection字段最常用于客户端要求服务器使用**TCP持久连接**，以便其他请求复用。

<div align=center><img src=Pictures\HTTP字段1.jpg width=60%></div>

HTTP/1.1版本的默认连接都是持久连接，但为了兼容老版本的HTTP，需要指定Connection首部字段的值为Keep-Alive。

#### 请求体

作用：存放**需发送给服务器的数据信息**。它是可选部分，如**GET请求就无请求数据**。

<div align=center><img src=Pictures\HTTP请求体.webp></div>


**关于请求报文的总结如下：**

<div align=center><img src=Pictures\HTTP请求报文1.webp></div>

**HTTP请求报文示例：**

<div align=center><img src=Pictures\HTTP请求报文示例.webp></div>


### HTTP响应报文

<div align=center><img src=Pictures\HTTP响应报文总结.webp></div>

| 状态码 |                        描述                        |
|:------:|:--------------------------------------------------:|
|   1xx  | 提示信息，请求被成功接收（中间状态，一般观察不到） |
|   2xx  |           成功，请求被成功处理（**200 ok**）           |
|   3xx  |               重定向相关（304 缓存）需要附加动作完成请求 |
|   4xx  |           客户端错误（**404 资源路径有误**）           |
|   5xx  |            服务器端错误（**500 程序有错**）            |


- 200 OK：请求在服务器端被正常处理；
- 204 No Content：服务器接收的请求已成功处理，但在返回的响应报文中不含实体的主体部分。另外，也不允许返回任何实体的主体。
- 301 Moved Permanently：请求的资源已被分配了新的URI
- 302 Found：请求的资源已被分配了新的URI，希望用户（本次）能使用新的URI访问。
- 403 Forbidden：对请求资源的访问被服务器拒绝了
- 404 Not Found：服务器上无法找到请求的资源
- 500 Internal Server Error：服务器端在执行请求时发生了错误
- 503 Service Unavailable：服务器暂时处于超负载或正在进行停机维护，现在无法处理请求


HTTP的响应报文包括：**状态行、响应头和响应体**

<div align=center><img src=Pictures\HTTP响应报文.jpg></div>

状态行：声明协议版本，状态码和状态描述；
响应头：声明客户端、服务器/报文的部分信息
响应体：存放需要发送的数据信息

<div align=center><img src=Pictures\HTTP响应报文.png></div>




#### 状态行

- 作用
  声明 协议版本，状态码，状态码描述
- 组成
  状态行有协议版本、状态码和状态信息组成
  
其中，空格不能省

<div align=center><img src=Pictures\HTTP响应报文状态行.webp></div>

**常见的HTTP相应状态码：**

状态码用以表示**网页服务器HTTP响应状态**的3位数字代码

200：请求被正常处理
404：服务器无法找到对应资源
500：服务器内部错误

| 状态码 |                        描述                        |
|:------:|:--------------------------------------------------:|
|   1xx  | 提示信息，请求被成功接收（中间状态，一般观察不到） |
|   2xx  |           成功，请求被成功处理（**200 ok**）           |
|   3xx  |               重定向相关（304 缓存）               |
|   4xx  |           客户端错误（**404 资源路径有误**）           |
|   5xx  |            服务器端错误（**500 程序有错**）            |


#### 响应头

- 作用：声明客户端、服务器 / 报文的部分信息
- 使用方式：采用`header(字段名):value(值)`的方式

<div align=center><img src=Pictures\HTTP响应报文响应头.webp width=70%></div>


#### 响应体

- 作用：存放需返回给客户端的数据信息
- 使用方式：和请求体是一致的，同样分为：任意类型的数据交换格式、键值对形式和分部分形式

<div align=center><img src=Pictures\HTTP响应报文响应体.webp></div>


#### 总结

<div align=center><img src=Pictures\HTTP响应报文总结.webp></div>


### 在浏览器输入网址后发生了什么

参考资料：https://labuladong.gitbook.io/algo/labuladong-he-ta-de-peng-you-men/jian-ru-wang-zhi-hou-dao-wang-ye-xian-shi-qi-jian-fa-sheng-le-shi-mo

<div align=center><img src=Pictures\打开一个网页的过程.webp></div>

#### 天龙八部

客户端输入URL回车，**DNS(Domain Name System)解析域名**得到服务器的IP地址，服务器在80**端口**监听客户端请求，端口通过**TCP/IP协议**建立连接。

**第一步：浏览器查找该域名的IP地址——DNS域名解析**

浏览器把域名发送给系统默认DNS服务器。如果该服务器本地有缓存，且缓存未过期，则直接返回结果否则向上一级DNS服务器查询，直到DNS根服务器。

**第二步：通过三次握手，建立了客户端和服务器之间的TCP连接：**

**第三步：浏览器根据解析得到的IP地址向web服务器发送一个HTTP请求**

浏览器知道了网址的对应服务器IP地址和端口，然后就通过TCP协议发起网络请求。

**第四步：服务器收到请求并进行处理**

**第五步：服务器返回一个响应**

**第六步：浏览器对该响应进行解码，渲染显示**

**第七步：页面显示完成后，浏览器发送异步请求。**

页面显示完成后客户端仍与服务器端保持着联系。它会持续与服务器保持联系来及时更新一些页面信息。

**第八步：关闭TCP连接**



<div align=center><img src=Pictures\浏览器输入网址.png></div>

#### 解析URL，产生HTTP请求信息

浏览器做的第一步工作就是要**对URL进行解析**，从而生成发送给Web服务器的请求信息：

<div align=center><img src=Pictures\浏览器输入网址1.png></div>

图中的长长的URL实际上是**请求服务器里的文件资源**。


对URL进行解析之后，浏览器确定了Web服务器和文件名，接下来就是根据这些信息来生成HTTP请求消息了。

<div align=center><img src=Pictures\浏览器输入网址2.png></div>

#### 2. DNS

通过浏览器解析URL并生成HTTP消息后，需要委托操作系统将消息发送给Web服务器。但在发送之前，还有一项工作需要完成，那就是查询服务器域名对应的IP地址，因为委托操作系统发送消息时，必须**提供通信对象的IP地址**。

域名的层级关系类似一个树状结构：
- 根DNS服务器
- 顶级域DNS服务器（com）
- 权威DNS服务器（server.com）

**域名解析的工作流程：**

- 客户端首先会发出一个DNS请求，问www.server.com的IP是啥，并发给**本地DNS服务器**（也就是客户端的TCP/IP设置中填写的DNS服务器地址）。

- 本地域名服务器收到客户端的请求后，如果**缓存里的表格**能找到www.server.com，则它直接返回IP地址。如果没有，本地DNS会去问它的**根域名服务器**：“老大，能告诉我www.server.com的IP地址吗？” 
  根域名服务器是最高层次的，**它不直接用于域名解析，但能指明一条道路**。 

- 根DNS收到来自本地DNS的请求后，发现后置是`.com`，说：“www.server.com这个域名归`.com`区域管理”，我给你**.com顶级域名服务器**地址给你，你去问问它吧。”

- 本地DNS收到顶级域名服务器的地址后，发起请求问“老二，你能告诉我www.server.com 的IP地址吗？”顶级域名服务器说：“我给你负责www.server.com区域的**权威DNS服务器**的地址，你去问它应该能问到”。

- 本地DNS于是转向问权威DNS服务器：“老三，www.server.com对应的IP是啥呀？” `server.com的权威DNS服务器`，它是**域名解析结果的原出处**。权威DNS服务器查询后将对应的IP地址 X.X.X.X 告诉本地DNS。

- **本地DNS再将IP地址返回客户端**，客户端和目标建立连接。

<div align=center><img src=Pictures\浏览器输入网址3.png></div>

#### 3. 协议栈

通过DNS获取到IP后，就可以把HTTP的传输工作交给操作系统中的协议栈。

协议栈的内部分为几个部分，分别承担不同的工作。上下关系是有一定的规则的，上面的部分会向下面的部分委托工作，下面的部分收到委托的工作并执行。

<div align=center><img src=Pictures\浏览器输入网址4.png width=80%></div>

应用程序（浏览器）通过调用Socket库，来委托协议栈工作。

协议栈的上半部分有两块，分别是负责收发数据的TCP和UDP协议，它们俩会接受应用层的委托执行收发数据的操作。

协议栈的下面一半是用IP协议控制网络包收发操作，在互联网上传数据时，数据会被切分成一块块的网络包，而将网络包发送给对方的操作就是由IP负责的。

此外IP中还包括ICMP协议和ARP协议：
- ICMP用于告知网络包传送过程中产生的错误以及各种控制信息。
- ARP用于根据IP地址查询相应的**以太网MAC地址**。


IP下面的网卡驱动程序负责控制网卡硬件，而最下面的网卡则负责完成实际的收发操作，也就是对网线中的信号执行发送和接收操作。

#### 4. TCP可靠传输

HTTP是基于TCP协议传输的。TCP传输数据之前，要先三次握手建立连接。TCP协议里面会有两个端口，一个是浏览器监听的端口（通常是随机生成的），一个是Web服务器监听的端口（**HTTP默认端口号是80**，**HTTPS默认端口号是443**）。


为了传输方便，在**传输层（TCP协议）**把从应用层处收到的数据（**HTTP请求报文**）进行分割，并在各个报文上打上标记序号及**端口号**后转发给网络层。

在双方建立了连接后，TCP报文中的数据部分就是存放`HTTP头部 + 数据`，组装好TCP报文之后，就需交给下面的网络层处理。

至此，网络包的报文如下图：

<div align=center><img src=Pictures\浏览器输入网址5.png width=80%></div>

<div align=center><img src=Pictures\TCP数据分割1.png></div>

#### 5. 远程定位IP

TCP模块在执行连接、收发、断开等各阶段操作时，都需要委托IP模块将数据封装成网络包发送给通信对象。

我们先看看IP报文头部的格式：

<div align=center><img src=Pictures\IP报文格式.png width=60%></div>

在IP协议里面需要有**源地址IP**和**目标地址IP**：

- 源地址IP，即是客户端输出的 IP 地址；
- 目标地址，即通过DNS域名解析得到的Web服务器IP。

因为HTTP是经过TCP传输的，所以在IP包头的协议号，要填写为06（十六进制），表示协议为TCP。

假设客户端有多个网卡，就会有多个IP地址，那IP头部的源地址应该选择哪个IP呢？

当存在多个网卡时，在填写源地址IP时，就需要判断到底应该填写哪个地址。这个判断相当于在多块网卡中判断应该使用哪个一块网卡来发送包。

这个时候就需要根据**路由表规则**，来判断哪一个网卡作为源地址IP。

至此，网络包的报文如下图：

<div align=center><img src=Pictures\浏览器输入网址6.png width=80%></div>

#### 6. 两点传输MAC

生成了IP头部之后，接下来网络包还需要在IP头部的前面加上MAC头部。

MAC头部是以太网使用的头部，它包含了接收方和发送方的MAC地址等信息：

<div align=center><img src=Pictures\MAC包头格式.png width=40%></div>

在MAC包头里需要发送方MAC地址和接收方目标MAC地址，用于两点之间的传输。

一般在TCP/IP通信里，MAC包头的协议类型只使用：
- 0800：IP协议
- 0806：ARP协议

**MAC发送方和接收方如何确认?**

发送方的MAC地址获取就比较简单了，MAC地址是在网卡生产时写入到ROM里的，只要将这个值读取出来写入到MAC头部就可以了。

接收方的MAC地址就有点复杂了，只要告诉以太网对方的MAC的地址，以太网就会帮我们把包发送过去，那么很显然这里应该填写对方的MAC地址。所以先得搞清楚应该把包发给谁，这个只要查一下**路由表**就知道了。在路由表中找到相匹配的条目，然后把包发给Gateway列中的IP地址就可以了。

**既然知道要发给谁，按如何获取对方的MAC地址呢？**

不知道对方MAC地址？不知道就**喊**呗。

此时就需要**ARP协议**帮我们找到路由器的MA 地址。

<div align=center><img src=Pictures\ARP广播.png width=60%></div>

ARP协议会在以太网中以**广播**的形式，对以太网所有的设备喊出：“这个IP地址是谁的？请把你的 MAC地址告诉我”。

然后就会有人回答：“这个IP地址是我的，我的MAC地址是 XXXX”。

如果对方和自己处于同一个子网中，那么通过上面的操作就可以得到对方的MAC地址。然后，我们将这个MAC地址写入MAC头部，MAC头部就完成了。

**好像每次都要广播获取，这不是很麻烦吗**

在后续操作系统会把本次查询结果放到一块叫做**ARP缓存**的内存空间留着以后用，不过缓存的时间就几分钟。

也就是说，在发包时：先查询ARP缓存，如果其中已经保存了对方的MAC地址，就不需要发送ARP查询，直接使用ARP缓存中的地址。而当ARP缓存中不存在对方MAC地址时，则发送ARP广播查询。

至此，网络包的报文如下图：

<div align=center><img src=Pictures\浏览器输入网址7.png width=80%></div>

#### 7. 出口 —— 网卡

IP生成的网络包只是存放在内存中的一串二进制数字信息，没有办法直接发送给对方。因此，我们需要将数字信息转换为电信号，才能在网线上传输，也就是说，这才是真正的数据发送过程。

负责执行这一操作的是网卡，要控制网卡还需要靠网卡驱动程序。

网卡驱动从IP模块获取到包之后，会将其复制到网卡内的缓存区中，接着会在其开头加上报头和起始帧分界符，在末尾加上用于检测错误的帧校验序列。

<div align=center><img src=Pictures\物理层数据包.png></div>

- 起始帧分界符是一个用来表示包起始位置的标记
- 末尾的FCS（帧校验序列）用来检查包传输过程是否有损坏

最后网卡会将包转为电信号，通过网线发送出去。

#### 8. 送别者 —— 交换机

下面来看一下包是如何通过交换机的。交换机的设计是将网络包原样转发到目的地。**交换机工作在MAC层，也称为二层网络设备**。

**交换机的包接收操作：**

首先，电信号到达网线接口，交换机里的模块进行接收，接下来交换机里的模块将电信号转换为数字信号。然后通过包末尾的FCS校验错误，如果没问题则放到缓冲区。这部分操作基本和计算机的网卡相同，但交换机的工作方式和网卡不同。

计算机的网卡本身具有MAC地址，并通过核对收到的包的接收方MAC地址判断是不是发给自己的，如果不是发给自己的则丢弃；相对地，交换机的端口不核对接收方MAC地址，而是直接接收所有的包并存放到缓冲区中。因此，和网卡不同，交换机的端口不具有MAC地址。

将包存入缓冲区后，接下来需要查询一下这个包的接收方MAC地址是否已经在MAC地址表中有记录了。

交换机的MAC地址表主要包含两个信息：
- 一个是设备的MAC地址，
- 另一个是该设备连接在交换机的哪个端口上。

<div align=center><img src=Pictures\交换机的MAC地址表.png width=80%></div>

如果收到的包的接收方MAC地址为`00-02-B3-1C-9C-F9`，则与图中表中的第3行匹配，根据端口列的信息，可知这个地址位于3号端口上，然后就可以通过交换电路将包发送到相应的端口了。

所以，交换机根据MAC地址表查找MAC地址，然后将信号发送到相应的端口。

**当MAC地址表找不到指定的MAC地址会怎么样？**

地址表中找不到指定的MAC地址，这可能是因为具有该地址的设备还没有向交换机发送过包，或者这个设备一段时间没有工作导致地址被从地址表中删除了。

这种情况下，交换机无法判断应该把包转发到哪个端口，只能将包转发到除了源端口之外的所有端口上，无论该设备连接在哪个端口上都能收到这个包。

这样做不会产生什么问题，因为以太网的设计本来就是将包发送到整个网络的，然后只有相应的接收者才接收包，而其他设备则会忽略这个包。

**这样做会发送多余的包，会不会造成网络拥塞呢？**

其实完全不用过于担心，因为发送了包之后目标设备会作出响应，只要返回了响应包，交换机就可以将它的地址写入MAC地址表，下次也就不需要把包发到所有端口了。局域网中每秒可以传输上千个包，多出一两个包并无大碍。

此外，如果接收方MAC地址是一个广播地址，那么交换机会将包发送到除源端口之外的所有端口。

以下两个属于广播地址：
- MAC地址中的`FF:FF:FF:FF:FF:FF`
- IP地址中的`255.255.255.255`

#### 9. 出境大门 —— 路由器

##### 路由器与交换机的区别

网络包经过交换机之后，现在到达了路由器，并在此被转发到下一个路由器或目标设备。这一步转发的工作原理和交换机类似，也是通过查表判断包转发的目标。

不过在具体的操作过程上，路由器和交换机是有区别的：
- 因为路由器是基于IP设计的，俗称三层网络设备，路由器的各个端口都具有MAC地址和IP地址；
- 而交换机是基于以太网设计的，俗称二层网络设备，交换机的端口不具有MAC地址。

路由器实现了**不同网络之间的数据转发**，交换机实现了**特定网络内的数据交换**！

- 工作层次不同：**交换机主要工作在数据链路层（第二层）路由器工作在网络层（第三层）**。
- 转发依据不同：交换机转发所依据的对象时：MAC地址。（物理地址）路由转发所依据的对象是：IP地址。（网络地址）
- 主要功能不同：交换机主要用于组建局域网，而路由主要功能是将由交换机组好的局域网相互连接起来，或者接入Internet。
- 交换机能做的，路由都能做。交换机不能分割广播域，路由可以。路由还可以提供防火墙的功能。路由配置比交换机复杂。
- 价格不同交换机是看门大爷，路由是邮差。



**路由器基本原理**

路由器的端口具有MAC地址，因此它就能够成为以太网的发送方和接收方；同时还具有IP地址，从这个意义上来说，它和计算机的网卡是一样的。

当转发包时，首先路由器端口会接收发给自己的以太网包，然后路由表查询转发目标，再由相应的端口作为发送方将以太网包发送出去。

**路由器的包接收操作**

首先，电信号到达网线接口部分，路由器中的模块会将电信号转成数字信号，然后通过包末尾的FCS进行错误校验。

如果没问题则检查MAC头部中的接收方MAC地址，看看是不是发给自己的包，如果是就放到接收缓冲区中，否则就丢弃这个包。

总的来说，路由器的端口都具有MAC地址，只接收与自身地址匹配的包，遇到不匹配的包则直接丢弃。

**查询路由表确定输出端口**

完成包接收操作之后，路由器就会去掉包开头的MAC头部。

MAC头部的作用就是将包送达路由器，其中的接收方MAC地址就是路由器端口的MAC地址。因此，当包到达路由器之后，MAC头部的任务就完成了，于是MAC头部就会被丢弃。

接下来，路由器会根据MAC头部后方的IP头部中的内容进行包的转发操作。

转发操作分为几个阶段，首先是查询路由表判断转发目标：

<div align=center><img src=Pictures\路由器转发.png></div>

接下来就会进入包的**发送操作**：

首先，需要根据路由表的网关列判断对方的地址。
- 如果网关是一个IP地址，则这个IP地址就是我们要转发到的目标地址，还未抵达终点，还需继续需要路由器转发。
- 如果网关为空，则IP头部中的接收方IP地址就是要转发到的目标地址，也是就终于找到IP包头里的目标地址了，说明已抵达终点。

知道对方的IP地址之后，接下来需要**通过ARP协议根据IP地址查询MAC地址**，并将查询的结果作为接收方MAC地址。

路由器也有ARP缓存，因此首先会在ARP缓存中查询，如果找不到则发送ARP查询请求。

接下来是发送方MAC地址字段，这里填写输出端口的MAC地址。还有一个以太类型字段，填写0080（十六进制）表示IP协议。

网络包完成后，接下来会将其转换成电信号并通过端口发送出去。这一步的工作过程和计算机也是相同的。

发送出去的网络包会通过交换机到达下一个路由器。由于接收方MAC地址就是下一个路由器的地址，所以交换机会根据这一地址将包传输到下一个路由器。

接下来，下一个路由器会将包转发给再下一个路由器，经过层层转发之后，网络包就到达了最终的目的地。

在网络包传输的过程中，源IP和目标IP始终是不会变的，一直变化的是MAC地址，因为需要MAC地址在以太网内进行两个设备之间的包传输。

#### 10. 互相扒皮 —— 服务器与客户端

<div align=center><img src=Pictures\数据在网络分层模型中的格式.png></div>

数据包抵达服务器后，服务器会先扒开数据包的MAC头部，查看是否和服务器自己的MAC地址符合，符合就将包收起来。

接着继续扒开数据包的IP头，发现IP地址符合，根据IP头中协议项，知道自己上层是TCP协议。

于是，扒开TCP的头，里面有序列号，需要看一看这个序列包是不是我想要的，**如果是就放入缓存中然后返回一个ACK**，如果不是就丢弃。TCP头部里面还有端口号，**HTTP的服务器正在监听这个端口号**。于是，服务器自然就知道是HTTP进程想要这个包，于是就**将包发给HTTP进程**。

服务器的HTTP进程看到，原来这个请求是要访问一个页面，于是就把这个网页封装在HTTP响应报文里。

HTTP响应报文也需要穿上TCP、IP、MAC头部，不过这次是源地址是服务器IP地址，目的地址是客户端IP地址。穿好头部衣服后，从网卡出去，交由交换机转发到出城的路由器，路由器就把响应数据包发到了下一个路由器，就这样跳啊跳。

最后跳到了客户端的城门把手的路由器，路由器扒开IP头部发现是要找城内的人，于是又把包发给了城内的交换机，再由交换机转发到客户端。

客户端收到了服务器的响应数据包后，同样也非常的高兴，客户能拆快递了！于是，客户端开始扒皮，**把收到的数据包的皮扒剩HTTP响应报文后，交给浏览器去渲染页面**，一份特别的数据包快递，就这样显示出来了！

最后，客户端要离开了，**向服务器发起了TCP四次挥手**，至此双方的连接就断开了。

### HTTP版本发展

| 版本  | 产生时间  |  内容 | 发展现状  |
|---|---|---|---|
| HTTP/0.9	 | 1991年  | 不涉及数据包传输，规定客户端和服务器之间通信格式，只能GET请求  |  没有作为正式的标准 |
| HTTP/1.0  | 1996年  | 传输内容格式不限制，增加PUT、PATCH、HEAD、 OPTIONS、DELETE命令  | 正式作为标准  |
| HTTP/1.1  | 1997年  | **持久连接(长连接)**、节约带宽、HOST域、管道机制、分块传输编码  |2015年前使用最广泛   |
| HTTP/2  | 2015年  | **多路复用**、服务器推送、头信息压缩、二进制协议等  | 逐渐覆盖市场  |

Http1.1 比 Http1.0 多了以下优点：

- 引入**持久连接**，即**在同一个TCP的连接中可传送多个HTTP请求与响应**
- 多个请求与响应可同时进行、可重叠
- 引入更加多的请求头与响应头
  如与身份认证、状态管理和Cache缓存等机制相关的、HTTP1.0无host字段


#### HTTP处理长连接的方式

- 在HTTP/1.0 中默认使用**短连接**。也就是说，**客户端和服务器每进行一次HTTP操作，就建立一次连接，任务结束就中断连接**。当客户端浏览器访问的某个HTML或其他类型的Web页中包含有其他的Web资源（如：JavaScript 文件、图像文件、CSS 文件等），每遇到这样一个Web资源，浏览器就会重新建立一个HTTP会话。

- 而从HTTP/1.1起，默认使用**长连接**，用以保持连接特性。使用长连接的HTTP协议，会在响应头加入这行代码`Connection:keep-alive`。

  - 在使用长连接的情况下，**当一个网页打开完成后，客户端和服务器之间用于传输HTTP数据的TCP连接不会关闭**，客户端再次访问这个服务器时，会**继续使用这一条已经建立的连接**。

  - `Keep-Alive`不会永久保持连接，它有一个**保持时间**，可以在不同的服务器软件（如：Apache）中设定这个时间。实现长连接需要客户端和服务端都支持长连接。

<div align=center><img src=Pictures\短连接和长连接.jpg></div>


<div align=center><img src=Pictures\HTTP处理长连接.jpg></div>

#### 管道网络传输

HTTP/1.1采用了长连接的方式，这使得管道（pipeline）网络传输成为了可能。

即**可在同一个TCP连接里面，客户端可以发起多个请求，只要第一个请求发出去了，不必等其回来，就可以发第二个请求出去**，可以减少整体的响应时间。

举例来说，客户端需要请求两个资源。以前的做法是，在同一个TCP连接里面，先发送A请求，然后等待服务器做出回应，收到后再发出B请求。管道机制则是允许浏览器同时发出A请求和B请求。

<div align=center><img src=Pictures\管道网络传输.jpg></div>

但是服务器还是按照顺序，先回应A请求，完成后再回应B请求。要是前面的回应特别慢，后面就会有许多请求排队等着。

#### 队头阻塞

「请求 - 应答」的模式加剧了HTTP的性能问题。

因为当**顺序发送**的请求序列中的一个请求因为某种原因被阻塞时，在后面排队的所有请求也一同被阻塞了，会招致客户端一直请求不到数据，这也就是「队头阻塞」。

<div align=center><img src=Pictures\队头阻塞.jpg></div>




#### HTTP2

下图是Akamai公司建立的一个官方的演示，使用`HTTP/1.1`(1997年)和`HTTP/2`(2015年)同时请求379张图片，观察请求的时间，明显看出`HTTP/2`性能占优势：

<div align=center><img src=Pictures\Http1.1VS2.jpg></div>

`HTTP/2`采用**多路复用**技术：通过**单一的`HTTP/2`连接请求**发起**多重的请求-响应消息**，**多个请求stream共享一个TCP连接**，实现**多流并行**而**不是依赖建立多个TCP连接**。

HTTP2.0 的主要变化：

- HTTP2.0支持**多路复用**，**同一个连接可以并发处理多个请求**，方法是**把HTTP数据包拆为多个帧，并发有序的发送，根据序号在另一端进行重组，而不需要一个个HTTP请求顺序到达**；
  - HTTP/2是可以在一个连接中并发多个请求或回应，而不用按照顺序一一对应。移除了HTTP/1.1中的串行请求，**不需要排队等待**，也就**不会再出现「队头阻塞」问题**，降低了延迟，大幅度提高了连接的利用率。
  - 举例来说，在一个TCP连接里，服务器收到了客户端A和B的两个请求，如果发现A处理过程非常耗时，于是就回应A请求已经处理好的部分，接着回应B请求，完成后，再回应A请求剩下的部分。

<div align=center><img src=Pictures\多路复用.jpg></div>

- HTTP2.0支持**服务端推送**，就是服务端在HTTP请求到达后，除了返回数据之外，还推送了额外的内容给客户端；
  - HTTP/2在一定程度上改善了传统的「请求 - 应答」工作模式，服务不再是被动地响应，也可以主动向客户端发送消息。
  - 举例来说，**在浏览器刚请求HTML的时候，就提前把可能会用到的JS、CSS 文件等静态资源主动发给客户端，减少延时的等待**，也就是服务器推送（Server Push，也叫Cache Push）。

- HTTP2.0**压缩了请求头**，同时基本单位是**二进制帧流**，这样的数据占用空间更少；
  - 如果你同时发出多个请求，他们的头是一样的或是相似的，那么，协议会帮你消除重复的部分。这就是所谓的HPACK算法：在客户端和服务器同时维护一张头信息表，所有字段都会存入这个表，生成一个索引号，以后就不发送同样字段了，只发送索引号，这样就提高速度了。
  - HTTP/2不再像HTTP/1.1里的纯文本形式的报文，而是全面采用了**二进制格式**，头信息和数据体都是二进制，并且统称为帧（frame）：头信息帧和数据帧。这样虽然对人不友好，但是对计算机非常友好，因为计算机只懂二进制，那么收到报文后，无需再将明文的报文转成二进制，而是直接解析二进制报文，这增加了数据传输的效率。

- HTTP2.0适用于HTTPS场景，因为其在HTTP和TCP中间加了一层SSL层。

- HTTP/2的数据包**不是按顺序发送的**，同一个连接里面连续的数据包，可能属于不同的回应。因此，必须要对数据包做标记，指出它属于哪个回应。每个请求或回应的所有数据包，称为一个**数据流（Stream）**。每个数据流都标记着一个独一无二的编号，其中规定客户端发出的数据流编号为奇数， 服务器发出的数据流编号为偶数。客户端还可以指定数据流的优先级。优先级高的请求，服务器就先响应该请求。





## 什么是HTTPS

HTTPS是**身披SSL外壳的HTTP**。HTTPS是一种通过计算机网络进行**安全通信**的传输协议，**经由HTTP进行通信，利用SSL/TLS(TLS是传输层加密协议，前身是SSL协议(安全套接字层))建立全信道，加密数据包**。HTTPS使用的主要目的是**提供对网站服务器的身份认证**，同时**保护交换数据的隐私与完整性**。


### HTTP与HTTPS比较

#### 两者区别

- HTTP是超文本传输协议，信息是**明文传输**，存在安全风险的问题。HTTPS则解决HTTP不安全的缺陷，在TCP和HTTP网络层之间加入了SSL/TLS安全协议——**TLS(安全传输层协议Transport Layer Security)/SSL(安全套接字层Secure Sockets Layer)**，使得报文能够加密传输。
- **HTTP连接建立相对简单，TCP三次握手之后便可进行HTTP的报文传输**。而**HTTPS在TCP三次握手之后，还需进行SSL/TLS的握手**过程，才可进入加密报文传输。
- **HTTP的端口号是80，HTTPS的端口号是443**。
- HTTPS协议需要向CA（证书权威机构）申请数字证书，来保证服务器的身份是可信的。

<div align=center><img src=Pictures\HTTP与HTTPS的区别.webp></div>

#### HTTP特点

- 无状态：HTTP服务器不保存关于客户的任何信息。
    - 比如**访问一个网站需要反复进行登录操作**。
    - HTTP 是无状态的意思就是说**对于同一客户端的每一次请求服务器的处理都是一样的**，不会记录客户端的上一次访问，也不记得客户端访问过多少次，因此使得**服务器更能支持大量的并发操作**。
- 无连接：传送HTTP报文前，毋需建立HTTP连接
  - HTTP/1.1之前，由于无状态特点，每次请求需要通过TCP三次握手四次挥手，和服务器重新建立连接。虽然**HTTP是无连接，但是TCP是面向连接的**，所以客户端发起一个请求的时候还是要先建立连接，然后再进行HTTP通信，最后再断开连接。
    - 比如某个客户机在短时间多次请求同一个资源，服务器并不能区别是否已经响应过用户的请求，所以每次需要重新响应请求，需要耗费不必要的时间和流量。
  - 在HTTP协议1.0版本和之前的时候，HTTP都是属于这种<font color=red>非持续连接</font>的方式，即**每个请求访问都需要建立连接，释放连接**，即使在同一个页面下也是如此，这是因为一个页面通常存在多个请求。**非持续的连接不仅会增加了服务器的负担而且对于同一个界面的响应速度也会降低**。
  - HTTP 1.1 版本使用了<font color=red>持续连接</font>，持续连接就是客户端和服务器在建立连接后进行通信后，仍然在一段时间内保持连接，这样**客户端和服务器后续的请求就不用再进行建立释放的操作**。而且持续连接还可以进行非流水线的方式进行通信，就是下一次的客户端请求不用等上一次的服务器的答复就能发送，使得客户端的访问更加高效快速。
- 基于请求和响应：由客户端发起请求，服务端响应
- **不安全**：通信使用**明文**、请求和响应不会对通信方进行确认、无法保护数据的完整性。

针对**无状态**的解决策略：

- 通过Cookie/Session技术
- HTTP/1.1**持久连接**（HTTP **keep-alive**）方法，只要任意一端没有明确提出断开连接，则保持TCP连接状态，在请求首部字段中的`Connection: keep-alive`即为表明使用了持久连接。

Cookie通过在请求和响应报文中写入Cookie信息来控制客户端的状态。

相当于，在客户端第一次请求后，服务器会下发一个装有客户信息的「小贴纸」，后续客户端请求服务器的时候，带上「小贴纸」，服务器就能认得了。

<div align=center><img src=Pictures\Cookie.jpg></div>


#### HTTPS特点

**HTTP协议采用明文传输信息**，存在信息窃听、信息篡改和信息劫持的风险，而协议TLS/SSL具有身份验证、信息加密和完整性校验的功能，可以避免此类问题发生。


基于HTTP协议，通过SSL或TLS提供**加密**处理数据（采用**混合加密技术**，中间者无法直接查看明文内容）、**验证对方身份**（通过证书认证客户端访问的是自己的服务器）以及**数据完整性保护**（防止传输的内容被中间人**冒充**或者**篡改**）。


**HTTPS(Secure Hypertext Transfer Protocol)安全超文本传输协议**，是一个安全通信通道，它基于HTTP开发用于在客户计算机和服务器之间交换信息。它使用**安全套接字层**(SSL)进行信息交换，简单来说它是HTTP的安全版，是**使用TLS/SSL加密的HTTP协议**。

**SSL(Secure Sockets Layer)**目前的版本是3.0，被IETF（Internet Engineering Task Force）定义在RFC 6101中，之后IETF对SSL 3.0进行了升级，于是出现了**TLS 1.0(Transport Layer Security)**，定义在RFC 2246。实际上现在的HTTPS都是用的TLS协议。


    
**TLS/SSL全称安全传输层协议Transport Layer Security**，是**介于TCP和HTTP之间的一层安全协议**，不影响原有的TCP协议和HTTP协议，所以使用HTTPS基本上不需要对HTTP页面进行太多的改造。

<div align=center><img src=Pictures\HTTP与HTTPS网络层.jpg width=70%></div>






### HTTPS如何加密？


**HTTP由于是明文传输**，所以安全上存在以下三个风险：

- **窃听**风险，比如通信链路上可以获取通信内容，用户号容易没。
- **篡改**风险，比如强制植入垃圾广告，视觉污染，用户眼容易瞎。
- **冒充**风险，比如冒充淘宝网站，用户钱容易没。

HTTPS在HTTP与TCP层之间加入了SSL/TLS协议，可以很好的解决了上述的风险：
- 信息加密：交互信息无法被窃取，但你的号会因为「自身忘记」账号而没。
- 校验机制：无法篡改通信内容，篡改了就不能正常显示，但百度「竞价排名」依然可以搜索垃圾广告。
- 身份证书：证明淘宝是真的淘宝网，但你的钱还是会因为「剁手」而没。

**HTTPS是如何解决上面的三个风险的？**

- **混合加密**的方式(**对称加密和非对称加密结合**)实现信息的机密性，解决了**窃听**的风险（但由于非对称加密的特性，仍存在被冒充的危险）。
- **摘要(Hash)算法**的方式来实现完整性，它能够为数据生成独一无二的「指纹」，指纹用于校验数据的完整性，解决了**篡改**的风险。
- **将服务器公钥放入到数字证书**中，解决了**冒充**的风险。



通过混合加密的方式可以保证信息的机密性，**解决了窃听的风险**。HTTPS 采用的是**对称加密和非对称加密结合**的「混合加密」方式。

<div align=center><img src=Pictures\混合加密.jpg></div>

#### 对称加密

对称加密(Symmetrical Encryption)顾名思义就是指<font color=red>加密和解密时使用的密钥都是同样的密钥</font>。这种算法的<font color=red>复杂度低，速度快</font>，所以在传输数据的时候，使用的是对称加密算法。

这种算法🔑只有一把，**加密解密都用同一把钥匙**，一旦🔑泄露就全玩完了，会出现<font color=red>被窃听</font>的风险。只要**保证了密钥的安全性**，那么整个通信过程也就是具有了机密性。

<div align=center><img src=Pictures\对称加密.png></div>

<div align=center><img src=Pictures\对称加密1.png></div>

小灰和小红可以事先约定一种**对称加密方式**，并且**约定一个随机生成的密钥**。**后续的通信中**，信息发送方都使用密钥对信息加密，而信息接收方通过同样的密钥对信息解密。

虽然我们在后续的通信中对明文进行了加密，但是**第一次约定加密方式和密钥的通信仍然是明文**，**如果第一次通信就已经被拦截了，那么密钥就会泄露给中间人，中间人仍然可以解密后续所有的通信内容**。

比如我出于人道主义，想要帮助小明同学作弊，首先考试前我们会约定好一个暗号来传递选择题的答案，摸头发——A，摸耳朵——B，咳嗽——C，跺脚——D，于是一个加密方法就诞生了，这个加密方法只有我和小明知道，老师虽然看我抓耳挠腮但他顶多把我当成神经病，并没有直接证据说我作弊。

这种我和小明知道，别人不知道的加密方法就是一种对称加密算法，对称加密算法也是我们日常最常见的加密算法。这种算法🔑只有一把，**加密解密都用同一把钥匙**，一旦🔑泄露就全玩完了。

#### 非对称加密

非对称加密(Asymmetrical Encryption) 也被称为公钥加密，相对于对称加密来说，非对称加密是一种新的改良加密方式。密钥通过网络传输交换，它能够确保即使密钥被拦截，也不会暴露数据信息。**<font color=red>非对称加密中有两个密钥，一个是公钥，一个是私钥，公钥进行加密，私钥进行解密。公开密钥可供任何人使用，私钥只有你自己能够知道。但会出现被第三方冒充的风险！</font>**

<div align=center><img src=Pictures\非对称加密.jpg></div>



**将a和b相乘得出乘积c很容易，但要是想要通过乘积c推导出a和b极难。即对一个大数进行因式分解极难。**

非对称加密算法就多了两个概念——**公钥c**和私钥b。

用法如下：**公钥加密的密文只能用私钥解密，私钥加密的密文只能用公钥解密**。

公钥我们可以随便公开，因为别人知道了公钥毫无用处，经过公钥加密后的密文只能通过私钥来解密。而**想要通过公钥推导出a和b极难**。但很明显的是，**使用非对称加密效率不如对称加密，因为非对称加密需要有计算两个密钥的过程**。

非对称加密的一组秘钥对中，包含一个**公钥**和一个**私钥**。**明文既可以用公钥加密，用私钥解密；也可以用私钥加密，用公钥解密**。

<div align=center><img src=Pictures\非对称加密1.png></div>

在上述过程中，客户端在拿到服务器的公钥后，会生成一个**随机码** (用KEY表示，这个KEY就是**后续双方用于对称加密的密钥**)，然后客户端使用公钥把KEY加密后再发送给服务器，服务器使用私钥将其解密，这样双方就有了同一个密钥KEY，然后双方再使用KEY进行对称加密交互数据。在非对称加密传输KEY的输过程中，即便第三方获取了公钥和加密后的KEY，在没有私钥的情况下也无法破解KEY(**私钥存在于服务器**，泄露风险极小)，也就保证了接下来对称加密的数据安全。

**举例说明：**

在小灰和小红建立通信的时候，小红首先把自己的**公钥**Key1发给小灰；收到小红的公钥以后，**小灰自己生成一个用于对称加密的密钥Key2**，并且**用刚才接收的公钥Key1对Key2进行加密**，发送给小红；**小红利用自己非对称加密的私钥**，解开了公钥Key1的加密（**公钥Key1的加密只能用小红自己的私钥解开**），获得了Key2的内容。**从此以后，两人就可以<font color=red>利用Key2进行对称加密的通信</font>了**。在通信过程中，**即使中间人在一开始就截获了公钥Key1，由于不知道私钥是什么，也无从解密**。

中间人虽然不知道小红的私钥是什么，但是在截获了小红的公钥Key1之后，却可以偷天换日，**自己另外生成一对公钥私钥，把自己的公钥Key3发送给小灰**。

小灰不知道公钥被偷偷换过，以为Key3就是小红的公钥。于是按照先前的流程，用Key3加密了自己生成的对称加密密钥Key2，发送给小红。这一次通信再次被中间人截获，中间人先用自己的私钥解开了Key3的加密，获得Key2，然后再用当初小红发来的Key1重新加密，再发给小红。这样一来，两个人后续的通信尽管用Key2做了对称加密，但是中间人已经掌握了Key2，所以可以轻松进行解密。

<font color=red>根本原因是小灰无法确认自己收到的公钥是不是小红自己的</font>。


#### 摘要算法(Hash算法)

哈希函数的这种<font color=red>对**不同的输入**能够生成**不同的值**的特性使得无法找到两个具有相同哈希值的输入</font>。因此，如果两个文档经哈希转换后成为相同的值，就可以肯定它们是同一文档。

摘要算法用来实现完整性，能够为数据生成独一无二的「指纹」，用于**校验数据的完整性**，**解决了篡改的风险**。

<div align=center><img src=Pictures\校验完整性.jpg></div>

<font color=red>客户端在发送明文之前会通过摘要算法算出**明文的「指纹」**，发送的时候**把「指纹 + 明文」一同加密成密文后，发送给服务器**，服务器解密后，用**相同的摘要算法**算出发送过来的明文，通过比较**客户端携带的指纹**和**当前算出的指纹**做比较，若「指纹」相同，说明数据是完整的。</font>

HASH算法用于**验证数据的完整性**！

消息摘要算法的特点：

① 无论输入的消息有多长，计算出来的**消息摘要的长度总是固定的**。
② 消息摘要看起来是“随机的”。这些比特看上去是胡乱的杂凑在一起的。
③ 一般地，**只要输入的消息不同，对其进行摘要以后产生的摘要消息也必不相同；但相同的输入必会产生相同的输出**。
④ 消息摘要函数是无陷门的单向函数，即<font color=red>只能进行正向的信息摘要，而无法从摘要中恢复出任何的消息</font>，甚至根本就找不到任何与原信息相关的信息。
⑤ 好的摘要算法，无法找到两条消息，使它们的摘要相同。

**消息摘要(Message Digest)又称为数字摘要(Digital Digest)**。它是一个**唯一**对应一个消息或文本的**固定长度的值**，它由一个**单向Hash加密函数**对消息进行作用而产生。如果消息在途中改变了，则**接收者通过对收到的消息新产生的摘要与原摘要比较，就可知道消息是否被改变了**。因此消息摘要保证了消息的完整性。

**消息摘要采用单向Hash函数将需加密的明文“摘要”成一串128bit的密文，这一串密文亦称为数字指纹(Finger Print)，它有固定的长度，且不同的明文摘要成密文，其结果总是不同的，而同样的明文其摘要必定一致**。这样这串摘要便可成为验证明文是否是“真身”的“指纹”了。

- HASH函数的<font color=red>抗冲突性</font>使得如果一段明文稍有变化，哪怕只更改该段落的一个字母，通过哈希算法作用后都将**产生不同的值**。
- 而HASH算法的<font color=red>单向性</font>使得**要找到到哈希值相同的两个不同的输入消息，在计算上是不可能的**。所以数据的哈希值，即消息摘要，可以检验数据的完整性。

哈希函数的这种<font color=red>对不同的输入能够生成不同的值的特性使得无法找到两个具有相同哈希值的输入</font>。因此，如果两个文档经哈希转换后成为相同的值，就可以肯定它们是同一文档。所以，**当希望有效地比较两个数据块时，就可以比较它们的哈希值**。

消息摘要算法的主要特征是**加密过程不需要密钥**，并且**经过加密的数据无法被解密**，**只有输入相同的明文数据经过相同的消息摘要算法才能得到相同的密文**。

一般不会去解密摘要算法加密的数据到底是什么，只会比较两个消息的密文是否一致，判断这两个原本的数据是否一致。


摘要算法用来实现完整性，能够为数据生成独一无二的「指纹」，用于**校验数据的完整性**，**解决了篡改的风险**。

<div align=center><img src=Pictures\校验完整性.jpg></div>

客户端在发送明文之前会通过摘要算法算出**明文的「指纹」**，发送的时候把「指纹 + 明文」一同加密成密文后，发送给服务器，服务器解密后，用**相同的摘要算法**算出发送过来的明文，通过比较客户端携带的「指纹」和当前算出的「指纹」做比较，若「指纹」相同，说明数据是完整的。



#### 数字证书

<font color=red>解决“无法确认收到的内容是否为自己所请求的对象发来的”——解决被冒充问题！</font>

数字证书是一种权威性的电子文档，由权威公正的第三方机构，即CA中心签发的证书。它以数字证书为核心的加密技术可以对网络上传输的**信息进行加密和解密**、**数字签名**和**签名验证**，确保网上传递信息的机密性、完整性。使用了数字证书，即使您发送的信息在网上被他人截获，甚至您丢失了个人的账户、密码等信息，仍可以保证您的账户、资金安全。

**服务器给客户端发送的<font color=red>数字证书</font>包含<font color=red>服务器的公钥</font>和<font color=red>把证书内容生成一份“签名”——CA的数字签名(包含服务器的信息)</font>，这些都被CA用自己的<font color=red>私钥</font>加密了！**

<div align=center><img src=Pictures\数子证书工作流程.jpg></div>

通过数字证书的方式**保证服务器公钥的身份**，**解决冒充的风险**。

- 作为**服务端的小红**，首先把自己的**公钥Key1**发给证书颁发机构，向证书颁发机构申请证书。
- 证书颁发机构自己也有**一对公钥私钥**。**<font color=red>机构利用自己的私钥来加密Key1，并且通过<u>服务端网址等信息生成一个证书签名</u>，证书签名同样经过机构的私钥加密</font>**。证书制作完成后，机构把证书发送给了**服务端小红**。
- 当**客户端**小灰向小红请求通信的时候，小红**服务端不再直接返回自己的公钥**，而是**把自己申请的证书返回给小灰**。
- 小灰收到证书以后，要做的第一件事情是**验证证书的真伪**。需要说明的是，**各大浏览器和操作系统已经维护了所有权威证书机构的名称和公钥**。所以小灰只需要知道是哪个机构颁布的证书，就可以**从本地找到对应的机构公钥，<font color=red>解密出证书签名</font>**。
- 接下来，**客户端小灰<font color=red>按照同样的签名规则，自己也生成一个证书签名，如果两个签名一致，说明证书是有效的</font>**。验证成功后，小灰就可以放心地再次**利用机构公钥，解密出服务端小红的公钥Key1**。
- 像之前一样，小灰生成自己的**对称加密密钥Key2**，并且**用服务端公钥Key1加密Key2**，发送给小红。
- 最后，小红用自己的私钥解开加密，得到对称加密密钥Key2。于是**两人开始用Key2进行对称加密的通信**。


<div align=center><img src=Pictures\数字签名生成与验证.jpg></div>

**数字签名的制作过程：**

- CA拥有非对称加密的私钥和公钥。
- **CA对<font color=red>证书明文(服务器的公钥)信息</font>进行hash**。
- 对hash后的值**用私钥加密**，得到数字签名。

**<font color=red>明文</font>和<font color=red>数字签名</font>共同组成了<font color=red>数字证书</font>**，这样一份数字证书就可以颁发给网站了。


#### 中间人有可能篡改该证书吗？

**中间人可以<font color=red>更改明文(服务器公钥)</font>，但由于<font color=red>没有CA的私钥，因此无法更改数字签名)</font>。客户端收到被篡改的证书后，会发现<font color=red>原文和签名解密后的值不一致)</font>，则说明证书已被篡改，证书不可信。**

<font color=red>假设中间人**篡改了证书的原文**，<u>由于他**没有CA机构的私钥，所以无法得到此时加密后签名，无法相应地篡改签名**。浏览器收到该证书后会发现原文和签名解密后的值不一致，则说明证书已被篡改，证书不可信</u>，从而终止向服务器传输信息，防止信息泄露给中间人</font>。



#### 既然不可能篡改，那整个证书有可能被掉包吗？

假设有另一个网站B也拿到了CA机构认证的证书，它想搞垮网站A，想劫持网站A的信息。于是它成为中间人拦截到了A传给浏览器的证书，然后替换成自己的证书，传给浏览器，之后浏览器就会错误地拿到B的证书里的公钥了，会导致上文提到的漏洞。

其实这并不会发生，因为<font color=red>证书里包含了网站A的信息，包括域名，浏览器把证书里的域名与自己请求的域名比对一下就知道有没有被掉包了(在无法被篡改情况下)</font>。



**中间人是否可以自己也向权威机构申请一个证书，并且把小红发来的证书偷偷换成自己的证书呢？**

没有用！因为**证书的签名是由服务端网址等信息生成的，并且经过机构私钥加密**，中间人也无法篡改！

网站在使用HTTPS前，需要向“CA机构”申请颁发一份数字证书，**数字证书里有证书持有者、证书持有者的公钥等信息**，服务器把证书传输给浏览器，浏览器从证书里取公钥就行了，证书就如身份证一样，可以**证明“该公钥对应该网站”**。

然而这里又有一个显而易见的问题了，**证书本身的传输过程中，如何防止被篡改**？即如何证明证书本身的真实性？数字证书怎么防伪呢？解决这个问题我们就基本接近胜利了！


**如何放防止数字证书被篡改？**

我们**把证书内容生成一份“签名”**，比对证书内容和签名是否一致就能察觉是否被篡改。这种技术就叫<font color=red>数字签名</font>。

<div align=center><img src=Pictures\数字签名生成与验证.jpg></div>

**数字签名的制作过程：**

- CA拥有非对称加密的私钥和公钥。
- **CA对<font color=red>证书明文(服务器的公钥)信息</font>进行hash**。
- 对hash后的值**用私钥加密**，得到数字签名。

**明文和数字签名共同组成了数字证书**，这样一份数字证书就可以颁发给网站了。

那浏览器拿到服务器传来的数字证书后，如何验证它是不是真的？（有没有被篡改、掉包）

**浏览器验证过程：**

- 拿到证书，得到**明文T**，**数字签名S**。
- **用CA机构的公钥对S解密**（由于是浏览器信任的机构，所以浏览器保有它的公钥），得到S’。
- **用证书里说明的hash算法对明文T进行hash得到T’**。
- 比较S’是否等于T’，等于则表明证书可信。




**SSL协议的握手过程：**

<div align=center><img src=Pictures\数字证书.jpg></div>

- 第一步：爱丽丝给出支持SSL协议版本号，一个客户端随机数(**Client random**，请注意这是**第一个随机数**)，客户端支持的加密方法等信息；
- 第二步：鲍勃收到信息后，确认双方使用的加密方法，并返回数字证书，一个服务器生成的随机数(**Server random**，注意这是**第二个随机数**)等信息；
- 第三步：爱丽丝确认数字证书的有效性，然后生成一个新的随机数(**Premaster secret**)，然后使用数字证书中的公钥，加密这个随机数，发给鲍勃。
- 第四步：鲍勃使用自己的私钥，获取爱丽丝发来的随机数(即Premaster secret)；(第三、四步就是非对称加密的过程了)
- 第五步：爱丽丝和鲍勃**通过约定的加密方法(通常是AES算法)，使用前面三个随机数，生成对话密钥，用来加密接下来的通信内容**。




<div align=center><img src=Pictures\HTTPS连接建立过程.jpg></div>

SSL/TLS 协议建立的详细流程：
1. ClientHello
首先，由客户端向服务器发起加密通信请求，也就是ClientHello请求。
在这一步，客户端主要向服务器发送以下信息：
（1）客户端支持的SSL/TLS协议版本，如TLS 1.2版本。
（2）**客户端生产的随机数（Client Random）**，后面用于生产「会话秘钥」。
（3）客户端支持的密码套件列表，如RSA加密算法。
2. SeverHello
服务器收到客户端请求后，向客户端发出响应，也就是SeverHello。服务器回应的内容有如下内容：
（1）确认SSL/TLS协议版本，如果浏览器不支持，则关闭加密通信。
（2）**服务器生产的随机数（Server Random）**，后面用于生产「会话秘钥」。
（3）确认的密码套件列表，如RSA加密算法。
（4）**服务器的数字证书**。
3. 客户端回应
客户端收到服务器的回应之后，首先**通过浏览器或者操作系统中的CA公钥，确认服务器的数字证书的真实性**。
如果证书没有问题，客户端会从数字证书中取出服务器的公钥，然后使用它加密报文，向服务器发送如下信息：
（1）**一个随机数（pre-master key）**，该随机数会被服务器公钥加密。
（2）加密通信算法改变通知，表示随后的信息都将用「会话秘钥」加密通信。
（3）客户端握手结束通知，表示客户端的握手阶段已经结束。这一项同时把之前所有内容的发生的数据做个摘要，用来供服务端校验。
上面第一项的随机数是整个握手阶段的**第三个随机数**，这样**服务器和客户端就同时有三个随机数**，接着就用双方协商的加密算法，各自生成本次通信的「会话秘钥」。
4. 服务器的最后回应
服务器收到客户端的第三个随机数（pre-master key）之后，通过协商的加密算法，计算出本次通信的「会话秘钥」。然后，向客户端发生最后的信息：
（1）**加密通信算法改变通知**，表示随后的信息都将用「会话秘钥」加密通信。
（2）服务器握手结束通知，表示服务器的握手阶段已经结束。这一项同时把之前所有内容的发生的数据做个摘要，用来供客户端校验。

至此，整个SSL/TLS的握手阶段全部结束。接下来，客户端与服务器进入加密通信，就完全是使用普通的HTTP协议，只不过**用「会话秘钥」加密内容**。

**整个过程：**

- CA机构颁发数字证书给鲍勃；
- 爱丽丝和鲍勃**进行SSL握手**，爱丽丝通过**数字证书**确定鲍勃的身份；
- 爱丽丝和鲍勃传递三个随机数，第三个随机数通过非对称加密算法进行传递；
- 爱丽丝和鲍勃通过一个对称加密算法生成一个对话密钥，加密接下来的通信内容。

通信双方**通过对称加密来加密密文**，然后**使用非对称加密的方式来传递对称加密所使用的密钥**。这样**效率**和**安全**就都能保证了。



#### 为什么制作数字签名时需要hash一次？

一方面是**性能问题**，**非对称加密效率较差**，证书信息一般较长，比较耗时。而**hash后得到的是固定长度的信息**（比如用md5算法hash后可以得到固定的128位的值），这样加密解密就会快很多。另一方面是**安全**上的原因。


### HTTPS的工作过程

- 客户端**发送自己支持的加密规则给服务器**，代表告诉服务器要进行连接了；

- <font color=red>服务器从中选出一套**加密算法和hash算法**以及自己的身份信息（地址等）以**证书**的形式发送给浏览器，证书中包含服务器信息，加密公钥，证书的办法机构</font>；

- 客户端收到网站的证书之后要做下面的事情：
  - 验证证书的合法性；
  - 如果验证通过证书，浏览器会生成一串随机数，并用证书中的公钥进行加密；
  - 用约定好的hash算法计算握手消息，然后用生成的密钥进行加密，然后一起发送给服务器。

- 服务器接收到客户端传送来的信息，要做下面的事情：
  - 用私钥解析出密码，用密码解析握手消息，验证hash值是否和浏览器发来的一致；
  - 使用密钥加密消息；

- 如果计算法hash值一致，握手成功。

<div align=center><img src=Pictures\HTTPS工作过程.png></div>

HTTPS的整个通信过程可以分为两大阶段：
- **证书验证**
- **数据传输**。数据传输阶段又可以分为：
  - 非对称加密
  - 对称加密



1. 客户端请求HTTPS网址，然后连接到server的**443端口**(HTTPS默认端口，类似于**HTTP的80端口**)。

2. 采用HTTPS协议的服务器必须要有一套**数字CA(Certification Authority)证书**，证书是需要申请的，并由专门的数字证书认证机构(CA)通过非常严格的审核之后颁发的电子证书(当然了是要钱的，安全级别越高价格越贵)。颁发证书的同时会产生一个私钥和公钥。**私钥由服务端自己保存，不可泄漏**。**公钥**则是附带在证书的信息中，可以公开的。证书本身也附带一个**证书电子签名**，**这个签名用来验证证书的完整性和真实性，可以防止证书被篡改**。

3. 服务器响应客户端请求，将**证书**传递给客户端，证书包含**公钥**和大量**其他信息**，比如证书颁发机构信息，公司信息和证书有效期等。在Chrome浏览器中点击地址栏的锁标志，再点击证书就可以看到证书详细信息。

4. **客户端解析证书并对其进行验证(<font color=red>确认收到的公钥不会被篡改、调包</font>)**。如果<font color=red>证书不是可信机构颁布——被篡改(数字签名)</font>，或者<font color=red>证书中的域名与实际域名不一致——被调包</font>，或者**证书已经过期**，就会向访问者显示一个警告，由其选择是否还要继续通信。如果证书没有问题，客户端就会从服务器证书中取出服务器的**公钥A**。然后客户端还会**生成一个随机码KEY，并使用公钥A将其加密**。

5. 客户端把加密后的随机码KEY发送给服务器，作为后面**对称加密的密钥**。

6. 服务器在收到随机码KEY之后会**使用私钥B将其解密**。经过以上这些步骤，**客户端和服务器终于建立了安全连接**，完美解决了对称加密的密钥泄露问题，接下来就可以用对称加密愉快地进行通信了。

7. 服务器使用密钥 (随机码KEY)对数据进行对称加密并发送给客户端，客户端使用相同的密钥(随机码KEY)解密数据。

8. 双方使用对称加密愉快地传输所有数据。





### HTTPS 的优缺点？

- 优点：
  - 使用HTTPS协议可认证用户和服务器，确保数据发送到正确的客户机和服务器；
  - HTTPS协议是由SSL+HTTP协议构建的可进行加密传输、身份认证的网络协议，要比HTTP协议安全，可防止数据在传输过程中不被窃取、改变，确保数据的完整性；
  - HTTPS是现行架构下最安全的解决方案，虽然不是绝对安全，但它大幅增加了中间人攻击的成本。

- 缺点：
  - HTTPS协议**握手阶段比较费时**，会使页面的加载时间延长近 50%，增加10%到20%的耗电；
  - HTTPS连接缓存不如HTTP高效，会增加数据开销和功耗，甚至已有的安全措施也会因此而受到影响；
  - SSL**证书需要钱**，功能越强大的证书费用越高，个人网站、小网站没有必要一般不会用；
  - SSL**证书通常需要绑定IP**，不能在同一IP上绑定多个域名，IPv4资源不可能支撑这个消耗；
  - HTTPS协议的**加密范围也比较有限**，在黑客攻击、拒绝服务攻击、服务器劫持等方面几乎起不到什么作用。最关键的，SSL证书的信用链体系并不安全，特别是在某些国家可以控制CA根证书的情况下，中间人攻击一样可行。


### 代理

代理是一种有转发功能的应用程序，它扮演了位于**服务器和客户端“中间人”**的角色，接收由客户端发送的请求并转发给服务器，同时也接收服务器返回的响应并转发给客户端。代理不改变请求 URI，会直接发送给前方持有资源的目标服务器。

<div align=center><img src=Pictures\代理.jpg></div>


# DNS：因特网的目录服务

识别主机有两种方式，通过**主机名**或者**IP地址**。人们喜欢便于记忆的主机名标识方式，而路由器则喜欢定长的、有着层次结构的IP地址。为了折衷这些不同的偏好，我们需要一种能进行**主机名到IP地址转换的目录服务**。这就是**域名系统**(Domain Name System, DNS)的主要任务。

一个域名往往对应多个DNS地址：
<div align=center><img src=Pictures\一个域名对应多个DNS.jpg width=80%></div>

[浏览器中输入网址到返回页面的全过程](#在浏览器输入网址后发生了什么)

## DNS解析

<div align=center><img src=Pictures\DNS解析.jpg></div>


浏览器输入地址，然后浏览器这个进程去调操作系统某个库里的`gethostbyname`函数(例如，Linux GNU glibc标准库的gethostbyname函数)，然后呢这个**函数通过网卡给DNS服务器发UDP请求**，接收结果，然后将结果给返回给浏览器。

我们在用chrome浏览器的时候，其实会先去**浏览器的DNS缓存**里头查询，DNS缓存中没有，再去调用gethostbyname函数；gethostbyname函数在试图进行DNS解析之前**首先检查域名是否在本地Hosts**里，如果没找到再去DNS服务器上查。


### DNS在域名解析上用UDP

UDP具有TCP所望尘莫及的**速度优势**。

虽然TCP协议中植入了各种安全保障功能，但是在实际执行的过程中会**占用大量的系统开销**，无疑使速度受到严重的影响。反观UDP由于排除了信息可靠传递机制，将安全和排序等功能移交给上层应用来完成，极大降低了执行时间，使速度得到了保证。

客户端向DNS服务器查询域名，一般返回的内容都不超过512字节，用UDP传输即可。不用经过TCP三次握手，这样**DNS服务器负载更低，响应更快**。

**DNS中也有一个地方用到了TCP协议。那就是区域传送**！

DNS的规范规定了2种类型的DNS服务器，一个叫**主DNS服务器**，一个叫**辅助DNS服务器**。在一个区中主DNS服务器从自己本机的数据文件中读取该区的DNS数据信息，而辅助DNS服务器则从区的主DNS服务器中读取该区的DNS数据信息。**当一个辅助DNS服务器启动时，它需要与主DNS服务器通信，并加载数据信息，这就叫做区传送(zone transfer)。这种情况下，使用TCP协议**。

这里之所以用TCP是因为**从主DNS上复制内容，需要保证可靠性**；并且**TCP协议传输的内容多**(UDP协议最大只能传512字节)！


### DNS如何做域名解析

<div align=center><img src=Pictures\DNS服务器的层次结构.jpg></div>

`www.tmall.com`对应的真正的域名为`www.tmall.com.`。末尾的`.`称为**根域名**，因为每个域名都有根域名，因此通常省略。

根域名的下一级，叫做**顶级域名**（top-level domain，缩写为TLD），比如`.com`、`.net`；

再下一级叫做**次级域名**（second-level domain，缩写为SLD），比如`www.tmall.com`里面的`.tmall`，这一级域名是用户可以注册的；

再下一级是**主机名**（host），比如`www.tmall.com`里面的`www`，又称为**三级域名**，这是用户在自己的域里面为服务器分配的名称，是用户可以任意分配的。

#### 分级查询

- 先在**本机的DNS**里头查，如果有就直接返回了；
- **本机DNS里头发现没有，就去根服务器里查**。根服务器发现这个域名是属于`com`域，因此根域DNS服务器会返回它所管理的`com`域中的DNS服务器的IP地址，意思是**虽然我不知道你要查的那个域名的地址，但你可以去`com`域问问看**；
- 本机的DNS接到又会向`com`域的DNS服务器发送查询消息。`com`域中也没有`www.tmall.com`这个域名的信息，和刚才一样，`com`域服务器会返回它下面的`tmall.com`域的DNS服务器的IP地址。

以此类推，只要重复前面的步骤，就可以顺藤摸瓜找到目标DNS服务器。



# 运输层端口

两个计算机中的进程要互相通信，不仅必须知道对方的**IP地址**(为了**找到对方的计算机**)，而且还要知道对方的**端口号**(为了找到对方计算机中的**应用进程**)。

- 应用层所有的应用进程都可以通过运输层再传送到IP层（网络层），这就是**复用**。
- 运输层从IP层收到数据后必须交付指明的应用进程。这就是**分用**。

显然，**给应用层的每个应用进程赋予一个非常明确的标志**是至关重要的。


一个进程（作为网络应用的一部分）有一个或多个**套接字**(socket)，它相当于**从网络向进程传递数据和从进程向网络传递数据的门户**。因此，**在接收主机中的运输层实际上并没有直接将数据交付给进程，而是将数据交给了一个中间的套接字**。由于在任一时刻，在接收主机上可能有不止一个套接字，所以**每个套接字都有唯一的标识符**。标识符的格式取决于它是UDP还是TCP套接字。

<div align=center><img src=Pictures\端口.jpg></div>

套接字用(**IP地址：端口号**)表示，区分**不同应用程序进程间的网络通信和连接**，主要有3个参数：
- 通信的目的IP地址
- 使用的传输层协议(TCP或UDP)
- 使用的端口号


将**运输层报文段**中的数据**交付到正确的套接字**的工作称为**多路分解**(demultiplexing)。

在源主机**从不同套接字中收集数据块，并为每个数据块封装上首部信息**(这将在以后用于分解)从而生成报文段，然后将报文段传递到网络层，所有这些工作称为**多路复用**(multiplexing)。

运输层多路复用要求：
- 套接字有**唯一标识符**；
- 每个报文段有**特殊字段**来**指示该报文段所要交付到的套接字**。

这些特殊字段是**源端口号字段**(source port number field)和**目的端口号字段**(destination port number field) 。

端口号是一个**16比特**的数，其大小在**0 ~ 65535**之间。**0 ~ 1023**范围的端口号称为**周知端口号**(well-known portnumber)，是受限制的，这是指它们**保留给诸如HTTP(它使用端口号80)和FTP(它使用端口号21)之类的周知应用层协议来使用**。


# TCP与UDP

## TCP和UDP的比较

|              |                     UDP                    |                   TCP                  |
|:------------:|:------------------------------------------:|:--------------------------------------:|
|   是否连接   |                   无连接                   |                面向连接                |
|   是否可靠   |    不可靠传输，不使用流量控制和拥塞控制    |    可靠传输，使用流量控制和拥塞控制    |
| 连接对象个数 | 支持一对一，一对多，多对一和多对多交互通信 |            只能是一对一通信            |
|   传输方式   |                  面向报文                  |               面向字节流               |
|   首部开销   |             首部开销小，仅8字节            |       首部最小20字节，最大60字节       |
|   适用场景   | 适用于**实时应用**（IP电话、视频会议、直播等） | 适用于要求**可靠传输**的应用，例如文件传输 |

<div align=center><img src=Pictures/TCPvsUDP.webp></div>


**UDP是面向报文的**

发送方的UDP对应用程序交下来的报文，在添加首部后就向下交付IP层。UDP对应用层交下来的报文，**既不合并，也不拆分**，而是保留这些报文的边界。因此，应用程序必须**选择合适大小的报文**。


**面向字节流**

TCP不像UDP一样那样一个个报文独立地传输，而是**在不保留报文边界的情况下以字节流方式进行传输**。

消息是「没有边界」的，所以**无论消息有多大都可以进行传输**。并且消息是「有序的」，当「前一个」消息没有收到的时候，即使它先收到了后面的字节，那么也不能扔给应用层去处理，同时对「重复」的报文会自动丢弃。


## TCP/IP网络模型

TCP/IP模型是互联网的基础，它是一系列网络协议的总称。这些协议可以划分为四层，分别为链路层、网络层、传输层和应用层：

- 链路层：负责封装和解封装IP报文，发送和接受ARP/RARP报文等。
- 网络层：负责路由以及把**分组报文**(IP数据报)发送给目标网络或主机。
- 传输层：负责对报文进行分组和重组，并以**TCP或UDP协议**格式封装报文。
- 应用层：负责向用户提供应用程序，比如**HTTP**、FTP、Telnet、**DNS**、SMTP等。

<div align=center><img src=Pictures\TCPIP网络模型.png></div>

## UDP

UDP协议全称是**用户数据报协议(User Datagram Protocol)**，在网络中它与TCP协议一样用于处理数据包，是一种**无连接**的协议。UDP有**不提供数据包分组、组装**和不能对数据包进行排序的缺点，也就是说，当报文发送之后，是**无法得知其是否安全完整到达**的。

### UDP特点

无连接的、不可靠的、面向报文、无拥塞控制——速度快，消息易丢失：

<div align=center><img src=Pictures\UDP特点.png></div>

#### 面向无连接

首先UDP是不需要和TCP一样在发送数据前进行三次握手建立连接的，**想发数据就可以开始发送了**。并且也**只是数据报文的搬运工**，**不会对数据报文进行任何拆分和拼接操作**。

- 在发送端，应用层将数据传递给传输层的UDP协议，UDP只会给数据增加一个UDP头标识下是UDP协议，然后就传递给网络层了；
- 在接收端，网络层将数据传递给传输层，UDP只去除IP报文头就传递给应用层，不会任何拼接操作。
  
#### 有单播，多播，广播的功能

UDP不止支持一对一的传输方式，同样支持一对多，多对多，多对一的方式，也就是说UDP提供了单播，多播，广播的功能。

#### UDP是面向报文的

发送方的UDP对应用程序交下来的报文，在添加首部后就向下交付IP层。UDP对应用层交下来的报文，**既不合并，也不拆分**，而是保留这些报文的边界。因此，应用程序必须**选择合适大小的报文**。

#### 不可靠性

首先不可靠性体现在**无连接上**，通信都不需要建立连接，想发就发，这样的情况肯定不可靠。

并且收到什么数据就传递什么数据，并且也不会备份数据，发送数据也**不会关心对方是否已经正确接收到数据了**。

再者网络环境时好时坏，但是UDP因为**没有拥塞控制**，一直会以恒定的速度发送数据。即使网络条件不好，也不会对发送速率进行调整。这样实现的弊端就是在**网络条件不好的情况下可能会导致丢包**，但是优点也很明显，在某些**实时性要求高的场景**（比如**电话会议**）就需要**使用UDP**而不是TCP。

<div align=center><img src=Pictures\UDP.gif></div>

UDP只会把想发的数据报文一股脑的丢给对方，并不在意数据有无安全完整到达。

#### 头部开销小，传输数据报文时高效

<div align=center><img src=Pictures\UDPHeader.png></div>

UDP头部包含了以下几个数据：

- 两个十六位的端口号，分别为**源端口**（可选字段）和**目标端口**
- 整个数据报文的长度
- 整个数据报文的检验和（IPv4可选字段），该字段用于发现头部信息和数据中的错误
  
因此UDP的头部开销小，只有八字节，相比TCP的至少二十字节要少得多，在传输数据报文时是很高效的。

### UDP应用场景

要求通信速度高的场景：
- 域名转换：DNS协议
- 文件传输：FTP协议
- 网络管理：SNMP协议
- 远程文件服务器：NFS协议


### 报文段格式

UDP的报文段共有2个字段：数据字段和首部字段(8字节、4个字段)：
<div align=center><img src=Pictures\UDP报文段.webp width=80%></div>

<div align=center><img src=Pictures\UDP报文段1.webp width=80%></div>



## TCP

TCP协议全称是**传输控制协议(Transmission Control Protocol)**，是一种**面向连接的、可靠的、基于字节流**的**传输层**通信协议，流就是指不间断的数据结构，你可以把它想象成排水管中的水流。基于TCP的**应用层**协议有**HTTP**、SMTP、FTP、TELNET和POP3。

### TCP特点

**数据传输可靠**，但因为需要建立连接、发送确认包等操作，导致**效率低**！

<div align=center><img src=Pictures\TCP特点.png></div>

**面向连接**

面向连接，是指发送数据之前必须在两端建立连接。建立连接的方法是**三次握手**，这样能建立可靠的连接。建立连接，是为数据的可靠传输打下了基础。

**仅支持单播传输**

每条TCP传输连接只能有两个端点，只能进行**点对点**的数据传输，不支持多播和广播传输方式。

**面向字节流**
TCP不像UDP一样那样一个个报文独立地传输，而是**在不保留报文边界的情况下以字节流方式进行传输**。

消息是「没有边界」的，所以**无论消息有多大都可以进行传输**。并且消息是「有序的」，当「前一个」消息没有收到的时候，即使它先收到了后面的字节，那么也不能扔给应用层去处理，同时对「重复」的报文会自动丢弃。

**可靠传输**

**对于可靠传输，判断丢包，误码靠的是TCP的段编号以及确认号**。TCP为了保证报文传输的可靠，就给每个包一个序号，同时序号也保证了传送到接收端实体的包的按序接收。然后接收端实体对已成功收到的字节发回一个相应的确认(ACK)；如果发送端实体在合理的往返时延(RTT)内未收到确认，那么对应的数据（假设丢失了）将会被重传。

**提供拥塞控制**

当网络出现拥塞的时候，TCP能够减小向网络注入数据的速率和数量，缓解拥塞。

**TCP提供全双工通信**

TCP允许通信双方的应用程序在任何时候都能发送数据，因为TCP连接的两端都设有缓存，用来临时存放双向通信的数据。当然，TCP可以立即发送一个数据段，也可以缓存一段时间以便一次发送更多的数据段（最大的数据段大小取决于MSS）。



### TCP应用场景

要求**通信数据可靠**时，即数据要准确无误地传递给对方：

- 传输文件：HTTP、HTTPS、FTP等协议；
- 传输邮件：POP、SMTP等协议；
- 远程终端接入：TELNET协议。
  

### 报文段格式

- TCP虽面向字节流，但传送的**数据单元**为**报文段**；
- 报文段 = **首部 + 数据** 2部分
  
TCP的全部功能体现在它首部中各字段的作用，首部前20个字符固定、后面有4n个字节是根据需而增加的选项，故**TCP首部最小长度为20字节**。

<div align=center><img src=Pictures\TCP报文.webp></div>

**ACK：确认标记位；ack：确认号！**

<div align=center><img src=Pictures\TCP报文1.png></div>

<div align=center><img src=Pictures\TCP报文头.png></div>

- **源端口号**和**目标端口号**是不可少的，如果没有这两个端口号，数据就不知道应该发给哪个应用。

- **序列号(seq)**：在建立连接时由计算机生成的随机数作为其初始值，通过**SYN包**传给接收端主机，每发送一次数据，就「累加」一次该「数据字节数」的大小。用来**解决<font color=red>网络包乱序</font>问题**。
- **确认应答号(ack)**：指下一次「期望」收到的数据的序列号，发送端收到这个确认应答以后可以认为在这个序号以前的数据都已经被正常接收。**用来解决<font color=red>不丢包</font>的问题**。
- 控制位：
  - ACK：该位为1时，**确认应答**的字段变为有效，TCP规定除了最初建立连接时的SYN包之外该位必须设置为1。
  - RST：该位为1时，表示TCP连接中出现异常必须强制断开连接。
  - SYN：该位为1时，表示**希望建立连接**，并在其「序列号」的字段进行序列号初始值的设定。
  - FIN：该位为1时，表示今后不会再有数据发送，希望断开连接。当通信结束希望断开连接时，通信双方的主机之间就可以相互交换FIN位为1的TCP段。
- 窗口大小。TCP要做流量控制，通信双方各声明一个窗口（缓存大小），标识自己当前能够的处理能力，别发送的太快，撑死我，也别发的太慢，饿死我。


### TCP分割数据——MSS与MTU

如果HTTP请求消息比较长，超过了MSS的长度，这时TCP就需要把HTTP的数据拆解成一块块的数据发送，而不是一次性发送所有数据。

<div align=center><img src=Pictures\TCP数据分割.png></div>

- MTU(Maximum Transmission Unit——**最大传输单元**)：一个网络包的最大长度，以太网中一般为1500字节。
- MSS(Maximum Segment Size——**最大报文段大小**)：除去IP和TCP头部之后，一个网络包所能容纳的TCP数据的最大长度。

数据会被以MSS的长度为单位进行拆分，拆分出来的每一块数据都会被放进单独的网络包中。也就是在每个被拆分的数据加上TCP头信息，然后交给IP模块来发送数据。

<div align=center><img src=Pictures\TCP数据分割1.png></div>


### TCP三次握手连接过程


<div align=center><img src=Pictures\TCP三次握手.webp width=80%></div>
<div align=center><img src=Pictures\TCP三次握手1.png></div>

成功进行TCP的三次握手后，就建立起一条TCP连接，即可传送应用层数据。因为TCP提供的是全双工通信，故通信双方的应用进程在任何时候都能发送数据；**三次握手期间，任何一次未收到对面的回复，则都会重发**。

**<font color=red>三次握手建立连接的首要目的是<u>同步序列号</u>。只有同步了序列号才有可靠传输(TCP实现可靠传输的方式之一，是通过序列号与确认应答。)，TCP许多特性都依赖于序列号实现，比如流量控制、丢包重传等</font>**。这也是三次握手中的报文称为SYN的原因，SYN的全称就叫**Synchronize Sequence Numbers**（同步序列号）。



<div align=center><img src=Pictures\TCP报文1.png></div>




建立一个TCP连接的过程为（三次握手的过程）：

<div align=center><img src=Pictures/三次握手.gif></div>

<div align=center><img src=Pictures/三次握手.jpg></div>

最开始的时候客户端和服务器都是处于CLOSED状态。主动打开连接的为客户端，被动打开连接的是服务器。

在三次握手建立连接的阶段，是不会传输TCP报文段的，传输的是`传输控制块（TCB）`，**传输控制块TCB(`Transmission Control Block`)**<font color=red>存储了每一个连接中的一些重要信息</font>，如：TCP连接表，指向发送和接收缓存的指针，指向重传队列的指针，当前的发送和接收序号等等。

- TCP`服务器进程`先创建`传输控制块TCB`，时刻准备接受客户进程的连接请求，此时服务器就进入了`LISTEN`（监听）状态；

- TCP`客户进程`也是先创建**传输控制块TCB[SYN=1, seq=x]**，然后向服务器发出`连接请求报文`，这时报文首部中的**同步位**`SYN=1`，同时选择一个**初始序列号**`seq=x`，此时，TCP客户端进程进入了`SYN-SENT（同步已发送状态）`状态。TCP规定，<font color=red>SYN报文段（SYN=1的报文段）不能携带数据，但需要消耗掉一个序号</font>。

- TCP`服务器`收到请求报文后，如果同意连接，则构建好`TCB[SYN=1, seq=y, ACK=1, ack=x+1]`发出`确认报文`。确认报文中应该**ACK=1，SYN=1**，**确认号是ack=x+1**，同时也要为自己初始化一个**序列号seq=y**，此时，TCP服务器进程进入了`SYN-RCVD（同步收到）`状态。<font color=red>这个报文也不能携带数据，但是同样要消耗一个序号</font>。

- TCP`客户进程`收到确认后，还要**向服务器给出确认**。确认报文的**ACK=1，ack=y+1**，自己的**序列号seq=x+1**，此时，TCP连接建立，客户端进入`ESTABLISHED（已建立连接）`状态。TCP规定，<font color=red>ACK报文段可以携带数据，但是如果不携带数据则不消耗序号</font>。

- 当`服务器`收到客户端的确认后也进入`ESTABLISHED`状态，此后双方就可以开始通信了。



<div align=center><img src=Pictures/TCP三次握手的状态变迁.webp width=80%></div>

- 第一步：客户端向服务器端发送包含了一个随机初始序号(`client_isn`)的**SYN报文段**。
  客户端的TCP首先向服务器端的TCP发送一个特殊的TCP报文段，**该报文段中不包含应用层数据**，但在报文段的首部中的一个标志位(`SYN比特`)被置为1。因此这个特殊报文段被称为**SYN报文段**。
  客户会随机地选择一个**初始序号**(`client_isn`)，并将此编号放置于该起始的TCP`SYN报文段`的序号字段中。
  该报文段会被封装在一个IP数据报中，并发送给服务器。

<div align=center><img src=Pictures/三次握手第一个报文.png></div>

- 第二步：服务器端接受到数据报后，向客户端发送**SYNACK报文段**(SYNACK segment)
  服务器从接收到的数据报中提取出TCP`SYN报文段`，为该TCP连接分配TCP缓存和变量，并向该客户TCP发送允许连接的报文段。
  在报文段的首部包含3个重要信息：**SYN**比特被置为1；**确认号字段ack**被置为`client_isn + 1`；服务器选择自己的**初始序号**(`server_isn`)。
  我收到了你发起建立连接的SYN分组，该分组带有初始序号`client_isn`。我同意建立该连接，我自己的初始序号为`server_isn`。**这次握手也是不可以携带数据的**。

<div align=center><img src=Pictures/三次握手第二个报文.png></div>

- 第三步：收到SYNACK报文段后，客户端向服务器端发送报文段，**对服务器的允许连接的报文段进行确认**。
  **确认号**字段`ack`被置为`server_isn + 1`，初始序号被置为`client_isn + 1`。**因为连接已经建立了，所以SYN比特被置为0**。**这次报文可以携带客户到服务器的数据**。

<div align=center><img src=Pictures/三次握手第三个报文.png></div>

一旦完成这3个步骤，客户和服务器主机就可以相互发送包括数据的报文段了。在以后每一个报文段中，SYN比特都将被置为0。 





### 为什么非得是三次握手？

这个问题的本质是，信道不可靠，但是通信双发需要就某个问题达成一致。而要解决这个问题，无论你在消息中包含什么信息，三次通信是理论上的最小值。所以三次握手不是TCP本身的要求，而是为了满足“**<font color=red>在不可靠信道上可靠地传输信息</font>**”这一需求所导致的。

<div align=center><img src=Pictures\三次握手2.jpg></div>

- **为何不直接在第一次握手就带上报文段消息，非要第三次才可以带？**

    因为<font color=red>TCP是要保证数据的不丢失且可靠</font>，如果在第一次就带上报文段消息，此次建立连接很有可能就会失败，那么就**不能保证数据的不丢失**了，在不可靠的机制上进行这种操作，换来的代价太大，每次发送报文段的资源也会增大，得不偿失；

    而**第三次握手的时候，客户端已经知道服务器端准备好了**，所以只要告诉服务器端自己准备好了就okay了，所以此时带上报文段信息没有任何问题。


为什么三次握手才可以初始化Socket、序列号和窗口大小并建立TCP连接？

- 建立一个TCP连接是需要客户端与服务器端达成三个信息的共识：
  - Socket：由IP地址和端口号组成；
  - 序列号：用来解决乱序问题等；
  - 窗口大小：用来做流量控制

- 三次握手的原因：
  - 三次握手才可以**阻止重复历史连接的初始化**（主要原因）
  - 三次握手才可以**同步双方的初始序列号**(**序列号是<font color=red>可靠传输</font>的一个关键因素**)
  - 三次握手才可以**避免资源浪费**

#### 避免历史连接

三次握手的首要原因是为了**防止旧的重复连接初始化造成混乱**。

网络环境是错综复杂的，往往并不是如我们期望的一样，先发送的数据包，就先到达目标主机，反而它很可能会由于网络拥堵等原因，会使得旧的数据包，先到达目标主机，那么这种情况下TCP三次握手是如何避免的呢？

<div align=center><img src=Pictures/三次握手避免历史连接.png></div>

客户端连续发送多次 SYN 建立连接的报文，在网络拥堵情况下：

- 一个「旧 SYN 报文」比「最新的 SYN 」 报文早到达了服务端，那么此时服务端就会回一个`SYN + ACK报文`给客户端；
- **客户端收到后可以根据自身的上下文，判断这是一个历史连接（序列号过期或超时）**，那么客户端就会发送RST报文给服务端，表示中止这一次连接。


**如果是两次握手连接，就不能判断当前连接是否是历史连接**。三次握手则可以在客户端（发送方）准备发送第三次报文时，客户端有足够的上下文来**判断当前连接是否是历史连接**：

- 如果是历史连接（序列号过期或超时），则第三次握手发送的报文是RST报文，以此中止历史连接；
- 如果不是历史连接，则第三次发送的报文是ACK报文，通信双方就会成功建立连接；

所以，TCP 使用三次握手建立连接的**最主要原因**是**防止历史连接初始化了连接**。


#### 同步双方初始序列号

TCP协议的通信双方，都必须维护一个序列号，**序列号是可靠传输的一个关键因素**，它的作用：

- 接收方可以去除重复的数据；
- 接收方可以根据数据包的序列号按序接收；
- 可以标识发送出去的数据包中，哪些是已经被对方收到的。

可见，**序列号在TCP连接中占据着非常重要的作用**，所以当客户端发送携带「初始序列号」的SYN报文的时候，需要服务端回一个ACK应答报文，表示客户端的SYN报文已被服务端成功接收。那当服务端发送「初始序列号」给客户端的时候，依然也要得到客户端的应答回应，这样一来一回，才能**确保双方的初始序列号能被可靠的同步**。

<div align=center><img src=Pictures/四次握手与三次握手.png></div>

**四次握手其实也能够可靠的同步双方的初始化序号，但由于第二步和第三步可以优化成一步，所以就成了「三次握手」**。

**而<font color=red>两次握手只保证了一方的初始序列号能被对方成功接收，没办法保证双方的初始序列号都能被确认接收</font>**。

#### 避免资源浪费

**如果只有「两次握手」**，当客户端的SYN请求连接在网络中阻塞，客户端没有接收到ACK报文，就会重新发送SYN。**由于没有第三次握手，服务器不清楚客户端是否收到了自己发送的建立连接的ACK确认信号，所以每收到一个SYN就只能先主动建立一个连接**，这会造成什么情况呢？

**如果客户端的SYN阻塞了，重复发送多次SYN报文，那么服务器在收到请求后就会建立多个冗余的无效链接，造成不必要的资源浪费**。

<div align=center><img src=Pictures/两次握手.png></div>


### SYN洪泛攻击

从上可看出：**服务端的TCP资源分配时刻 = 完成第二次握手时；而客户端的TCP资源分配时刻 = 完成第三次握手时**。这就使得服务器易于受到SYN洪泛攻击，即**同时多个客户端发起连接请求，从而需进行多个请求的TCP连接资源分配**。





### TCP四次挥手断开链接

<div align=center><img src=Pictures\TCP断开连接.webp></div>

<div align=center><img src=Pictures\TCP断开连接1.png></div>

TCP是全双工的，**在断开连接时两端都需要发送FIN和ACK**。

<div align=center><img src=Pictures/四次挥手.gif></div>

<div align=center><img src=Pictures/四次挥手.jpg></div>

<div align=center><img src=Pictures\TCP报文1.png></div>




### TCP四次挥手相关问题

#### 为什么TCP释放连接需四次挥手？

<div align=center><img src=Pictures\四次挥手1.jpg></div>

当主机向服务器发送“断开连接请求”，服务器返回“确认释放连接”时，只是完成了**单向断开**，即**服务器还是可以向主机发送数据，主机还是可以接收数据的**。

当服务器也发送“释放连接请求”，主机返回“连接释放确认”报文后，表示此时服务器已经没有数据要发送给主机，双方都无法通信了。


#### 为什么要有TIME_WAIT

- **原因一：防止旧连接的数据包**
  - **经过2MSL(Maximum Segment Lifetime)这个时间，足以让两个方向上的数据包都被丢弃，使得原来连接的数据包在网络中都自然消失，再出现的数据包一定都是新建立连接所产生的**。

- **原因二：保证连接正确关闭**
  - **等待足够的时间以确保最后的ACK能让被动关闭方接收，从而帮助其正常关闭**。

<div align=center><img src=Pictures/四次挥手.webp width=60%></div>

四次挥手过程只涉及了两种报文，分别是FIN和ACK：

- FIN就是结束连接的意思，谁发出FIN报文，就表示它将不会再发送任何数据，关闭这一方向上的传输通道；

- ACK就是确认的意思，用来通知对方：你方的发送通道已经关闭。

每个方向都需要一个FIN和一个ACK，因此通常被称为四次挥手。这里一点需要注意是：**主动关闭连接的，才有TIME_WAIT状态**。




当收到被动方发来的FIN报文后，主动方会立刻回复ACK，表示确认对方的发送通道已经关闭，接着就处于TIME_WAIT状态。

TIME_WAIT状态的连接，在主动方看来确实快已经关闭了。然后，被动方没有收到ACK报文前，还是处于LAST_ACK状态。

TIME-WAIT的状态尤其重要，主要是两个原因：

- 防止具有相同「四元组」的**旧数据包被收到**；
  TCP四元组可以唯一的确定一个连接，四元组包括如下：
  - 源地址
  - 源端口
  - 目的地址
  - 目的端口

- 保证「被动关闭连接」的一方能被正确的关闭，即**保证最后的ACK能让被动关闭方接收，从而帮助其正常关闭**。

**原因一：防止旧连接的数据包**

TIME-WAIT的一个作用是**防止收到历史数据，从而导致数据错乱**的问题。

假设TIME-WAIT没有等待时间或时间过短，被延迟的数据包抵达后会发生什么呢？

<div align=center><img src=Pictures\接收到历史数据的异常.webp></div>

上图黄色框框，服务端在关闭连接之前发送的**SEQ = 301**报文，被网络延迟了。**这时有相同端口的TCP连接被复用后，被延迟的SEQ = 301抵达了客户端，那么客户端是有可能正常接收这个过期的报文**，这就会产生数据错乱等严重的问题。

所以，TCP就设计出了这么一个机制，**经过2MSL这个时间，足以让两个方向上的数据包都被丢弃，使得原来连接的数据包在网络中都自然消失，再出现的数据包一定都是新建立连接所产生的**。


**原因二：保证连接正确关闭**

TIME-WAIT的另外一个作用是**等待足够的时间以确保最后的ACK能让被动关闭方接收，从而帮助其正常关闭**。

假设TIME-WAIT没有等待时间或时间过短，断开连接会造成什么问题呢？

<div align=center><img src=Pictures\没有确保正常断开的异常.webp></div>


上图**红色框框**客户端四次挥手的最后一个ACK报文如果在网络中被丢失了，此时如果客户端TIME-WAIT过短或没有，则就直接进入了CLOSE状态了，那么服务端则会一直处在LASE-ACK状态。

当客户端发起建立连接的SYN请求报文后，服务端会发送RST报文给客户端，连接建立的过程就会被终止。

MSL全称是`Maximum Segment Lifetime`，它定义了**一个报文在网络中的最长生存时间**（**报文每经过一次路由器的转发，IP头部的TTL字段就会减1，减到0时报文就被丢弃，这就限制了报文的最长存活时间**）。

**如果TIME-WAIT等待足够长**的情况就会遇到两种情况：

- 服务端正常收到四次挥手的最后一个ACK报文，则服务端正常关闭连接。
- 服务端没有收到四次挥手的最后一个ACK报文时，则会重发FIN关闭连接报文并等待新的ACK报文。
  
所以客户端在TIME-WAIT状态等待2MSL时间后，就可以保证双方的连接都可以正常的关闭。

#### 为什么客户端关闭连接前要等待2MSL时间？

- 即`TIME - WAIT`状态的作用是什么？
- `MSL` = 最长报文段寿命(`Maximum Segment Lifetime`)

**原因1：为了保证客户端发送的最后1个连接释放确认报文能到达服务器**，从而**使得服务器能正常释放连接**。否则，服务器将无法进入关闭状态。

<div align=center><img src=Pictures\四次挥手2.jpg></div>

**原因2：防止早已失效的连接请求报文出现在本连接中**。

客户端发送了最后1个连接释放请求确认报文后，再经过2MSL时间，则**可使本连接持续时间内所产生的所有报文段都从网络中消失**。即，**<font color=red>在下1个新的连接中就不会出现早已失效的连接请求报文</font>**。


#### 为什么不是4或者8MSL的时长呢？

你可以想象一个丢包率达到百分之一的糟糕网络，**连续两次丢包的概率只有万分之一，这个概率实在是太小了，忽略它比解决它更具性价比**。

因此，TIME_WAIT和FIN_WAIT2状态的最大时长都是2MSL，由于在Linux系统中，MSL的值固定为30秒，所以它们都是60秒。


#### 为何不能三次挥手呢？

- 首先如果**去掉最后一次挥手**，那么**服务器端就不知道自己要关闭的报文有没有传输成功**，可能半路上就失败了，但是此时客户端不知道，导致**客户端一直在等待服务器关闭**，但是此时服务器端直接就关闭了；(**客户端要等待足够的时间以确保最后的ACK能让被动关闭方接收，从而帮助其正常关闭**)
- 如果**中间的两次挥手合并**，那是肯定不行的，因为此时服务器端可能还有很多报文未处理完，此时直接关闭肯定会对传输有很大影响。



#### 为什么建立连接是三次握手，关闭连接确是四次挥手呢？

- 建立连接的时候， 服务器在LISTEN状态下，收到建立连接请求的SYN报文后，把ACK和SYN放在一个报文里发送给客户端。
- 而关闭连接时，服务器收到对方的FIN报文时，仅仅表示对方不再发送数据了但是还能接收数据，而自己也未必全部数据都发送给对方了，所以己方可以立即关闭，也可以发送一些数据给对方后，再发送FIN报文给对方来表示同意现在关闭连接，因此，己方ACK和FIN一般都会分开发送，从而导致多了一次。

#### 如果已经建立了连接，但是客户端突然出现故障了怎么办？

   TCP还设有一个保活计时器，显然，客户端如果出现故障，服务器不能一直等下去，白白浪费资源。服务器每收到一次客户端的请求后都会重新复位这个计时器，时间通常是设置为2小时，若两小时还没有收到客户端的任何数据，服务器就会发送一个探测报文段，以后每隔75秒钟发送一次。若一连发送10个探测报文仍然没反应，服务器就认为客户端出了故障，接着就关闭连接。

#### TIME_WAIT过多有什么危害？
如果服务器有处于TIME-WAIT状态的TCP，则说明是由服务器方主动发起的断开请求。

过多的TIME-WAIT状态主要的危害有两种：
- 第一是内存资源占用；
- 第二是对端口资源的占用，一个TCP连接至少消耗一个本地端口。

如果发起连接一方的TIME_WAIT状态过多，占满了所有端口资源，则会导致无法创建新连接。

**客户端受端口资源限制：**

客户端TIME_WAIT过多，就会导致端口资源被占用，因为端口就65536个，被占满就会导致无法创建新的连接。

**服务端受系统资源限制：**

由于一个四元组表示TCP连接，理论上服务端可以建立很多连接，服务端确实只监听一个端口但是会把连接扔给处理线程，所以理论上监听的端口可以继续监听。但是线程池处理不了那么多一直不断的连接了。所以当服务端出现大量TIME_WAIT时，系统资源被占满时，会导致处理不过来新的连接。



### 无差错传输

对比于UDP，TCP的传输是可靠的、无差错的。那么，为什么TCP的传输为什么是可靠的、无差错的呢？

TCP发送的报文段是交给IP层传送的。但**IP层只能提供尽最大努力服务**，也就是说，TCP下面的网络所提供的是不可靠的传输。因此，TCP必须采用适当的措施才能使得两个运输层之间的通信变得可靠！

**无差错**：即传输信道不出差错。
**发送和接收效率匹配**：即无论发送方以多快的速度发送数据，接收方总来得及处理收到的数据。

**无差错传输的解决方案**

核心思想：采用一些可靠传输协议，使得

- 出现差错时，让发送方重传差错数据：即<font color=red>出错重传</font>；
- 当接收方来不及接收收到的数据时，可通知发送方降低发送数据的效率：即<font color=red>速度匹配</font>

针对上述2个问题，分别采用的解决方案是：**自动重传协议**以及**流量控制和拥塞控制协议**。

#### 滑动窗口协议

- **TCP是每发送一个数据，都要进行一次确认应答。当上一个数据包收到了应答了，再发送下一个**。这样的传输方式有一个缺点：**数据包的往返时间越长，通信的效率就越低**。
- **为解决这个问题，TCP引入了窗口这个概念**。
  - 窗口的实现实际上是操作系统开辟的一个缓存空间，**发送方主机在等到确认应答返回之前，必须在缓冲区中保留已发送的数据**。如果按期收到确认应答，此时数据就可以从缓存区清除。那么有了窗口，就可以指定窗口大小，
  - **窗口大小就是指无需等待确认应答，而可以继续发送数据的最大值**。
  - 通常**窗口的大小是由接收方的窗口大小来决定的**。发送方发送的数据大小不能超过接收方的窗口大小，否则接收方就无法正常接收到数据。
  - **只有接收窗口向前滑动、接收方发送了确认帧时，发送窗口才有可能（只有发送方收到确认帧才是一定）向前滑动**

<div align=center><img src=Pictures/滑动窗口协议.png></div>

- **对于发送端**：
  - **每收到一个确认帧，发送窗口就向前滑动一个帧的距离(未收到确认帧，则窗口不移动)**
  - 当发送窗口内无可发送的帧时（即窗口内的帧全部是已发送但未收到确认的帧），发送方就会停止发送，直到收到接收方发送的确认帧使窗口移动，窗口内有可以发送的帧，之后才开始继续发送

- **对于接收端**：**当收到数据帧后，将窗口向前移动一个位置，并发回确认帧**，若收到的数据帧落在接收窗口之外，则一律丢弃。




TCP是每发送一个数据，都要进行一次确认应答。这个模式就有点像我和你面对面聊天，你一句我一句。但这种方式的缺点是效率比较低的。如果你说完一句话，我在处理其他事情，没有及时回复你，那你不是要干等着我做完其他事情后，我回复你，你才能说下一句话，很显然这不现实。

<div align=center><img src=Pictures/按数据包进行确认应答.png width=40%></div>

所以，这样的传输方式有一个缺点：**数据包的往返时间越长，通信的效率就越低**。

**为解决这个问题，TCP引入了窗口这个概念**。即使在往返时间较长的情况下，它也不会降低网络通信的效率。

那么有了窗口，就可以指定窗口大小，**窗口大小就是指无需等待确认应答，而可以继续发送数据的最大值**。

窗口的实现实际上是操作系统开辟的一个缓存空间，发送方主机在等到确认应答返回之前，必须在缓冲区中保留已发送的数据。如果按期收到确认应答，此时数据就可以从缓存区清除。

假设窗口大小为3个TCP段，那么发送方就可以「连续发送」3个TCP段，并且中途若有ACK丢失，可以通过「下一个确认应答进行确认」。如下图：

<div align=center><img src=Pictures/用滑动窗口方式并行处理.png width=60%></div>

图中的`ACK 600`确认应答报文丢失，也没关系，因为可以通过下一个确认应答进行确认，只要发送方收到了`ACK 700`确认应答，**就意味着700之前的所有数据「接收方」都收到了**。这个模式就叫**累计确认**或者**累计应答**。

##### 窗口大小由哪一方决定

TCP头里有一个字段叫Window，也就是窗口大小。这个字段是接收端告诉发送端自己还有多少缓冲区可以接收数据。于是发送端就可以根据这个接收端的处理能力来发送数据，而不会导致接收端处理不过来。

所以，通常**窗口的大小是由接收方的窗口大小来决定的**。发送方发送的数据大小不能超过接收方的窗口大小，否则接收方就无法正常接收到数据。



**发送方的滑动窗口**

下图就是发送方缓存的数据，根据处理的情况分成四个部分，其中深蓝色方框是发送窗口，紫色方框是可用窗口：

<div align=center><img src=Pictures/滑动窗口.png></div>

- 1 是已发送并收到 ACK确认的数据：1~31 字节
- 2 是已发送但未收到 ACK确认的数据：32~45 字节
- 3 是未发送但总大小在接收方处理范围内（接收方还有空间）：46~51字节
- 4 是未发送但总大小超过接收方处理范围（接收方没有空间）：52字节以后

在下图，当发送方把数据「全部」都一下发送出去后，可用窗口的大小就为0了，表明可用窗口耗尽，在没收到ACK确认之前是无法继续发送数据了。

<div align=center><img src=Pictures/可用窗口耗尽.png></div>

当收到之前发送的数据32-36字节的ACK确认应答后，如果发送窗口的大小没有变化，则滑动窗口往右边移动5个字节，因为有5个字节的数据被应答确认，接下来52-6字节又变成了可用窗口，那么后续也就可以发送52-56这5个字节的数据了：

<div align=center><img src=Pictures/滑动窗口1.png></div>

**程序是如何表示发送方的四个部分的呢？**

TCP滑动窗口方案**使用三个指针**来跟踪在**四个传输类别**中的每一个类别中的字节。其中两个指针是绝对指针（**指特定的序列号**），一个是相对指针（**需要做偏移**）：

<div align=center><img src=Pictures/滑动窗口三个指针.png></div>

- `SND.WND`：表示发送窗口的大小（**大小是由接收方指定的**）；
- `SND.UNA`：是一个绝对指针，它指向的是**已发送但未收到确认**的第一个字节的序列号，也就是#2的第一个字节。
- `SND.NXT`：也是一个绝对指针，它指向**未发送但可发送范围**的第一个字节的序列号，也就是#3的第一个字节。
- 指向#4的第一个字节是个相对指针，它需要SND.UNA指针加上SND.WND 大小的偏移量，就可以指向#4的第一个字节了。

那么可用窗口大小的计算就是：`可用窗口大 = SND.WND -（SND.NXT - SND.UNA）`。

**接收方的滑动窗口：**

接收窗口相对简单一些，根据处理的情况划分成三个部分：
- 1 + 2 是已成功接收并确认的数据（等待应用进程读取）；
- 3 是未收到数据但可以接收的数据；
- 4 未收到数据并不可以接收的数据；

<div align=center><img src=Pictures/滑动窗口三个指针1.png></div>

其中三个接收部分，使用两个指针进行划分:
- `RCV.WND`：表示接收窗口的大小，它会通告给发送方。
- `RCV.NXT`：是一个指针，它指向期望从发送方发送来的下一个数据字节的序列号，也就是#3的第一个字节。
- 指向#4的第一个字节是个相对指针，它需要RCV.NXT指针加上RCV.WND大小的偏移量，就可以指向#4的第一个字节了。

##### 发送窗口与接收窗口

<div align=center><img src=Pictures/滑动窗口协议.png></div>

- 对于发送端：
  - **每收到一个确认帧，发送窗口就向前滑动一个帧的距离(未收到确认帧，则窗口不移动)**
  - 当发送窗口内无可发送的帧时（即窗口内的帧全部是已发送但未收到确认的帧），发送方就会停止发送，直到收到接收方发送的确认帧使窗口移动，窗口内有可以发送的帧，之后才开始继续发送

<div align=center><img src=Pictures/滑动窗口协议1.webp></div>

- 对于接收端：**当收到数据帧后，将窗口向前移动一个位置，并发回确认帧**，若收到的数据帧落在接收窗口之外，则一律丢弃。

<div align=center><img src=Pictures/滑动窗口协议2.webp></div>


##### 滑动窗口协议的重要特性

- **只有接收窗口向前滑动、接收方发送了确认帧时，发送窗口才有可能（只有发送方收到确认帧才是一定）向前滑动**
- 停止-等待协议、后退N帧协议和选择重传协议只是在**发送窗口大小和接收窗口大小**上有所差别：
  - 停止等待协议：发送窗口大小=1，接收窗口大小=1；即**单帧滑动窗口**等于停止-等待协议
  - 后退N帧协议：发送窗口大小>1，接收窗口大小=1。
  - 选择重传协议：发送窗口大小>1，接收窗口大小>1。

- 当接收窗口的大小为1时，可保证帧有序接收。
- 数据链路层的滑动窗口协议中，窗口的大小在传输过程中是固定的（注意要与TCP的滑动窗口协议区别）



#### 重传机制

TCP实现可靠传输的方式之一，是**通过序列号与确认应答**。

在TCP中，当发送端的数据到达接收主机时，接收端主机会返回一个确认应答消息，表示已收到消息。

<div align=center><img src=Pictures/重传机制.png width=40%></div>

但在错综复杂的网络，并不一定能如上图那么顺利能正常的数据传输，万一数据在传输过程中丢失了呢？所以TCP针对数据包丢失的情况，会用重传机制解决。

接下来说说常见的重传机制：
- 超时重传
- 快速重传
- SACK
- D-SACK


##### 超时重传

重传机制的其中一个方式，就是在发送数据时，设定一个定时器，当超过指定的时间后，没有收到对方的ACK确认应答报文，就会重发该数据，也就是我们常说的超时重传。

TCP会在以下两种情况发生超时重传：
- 数据包丢失
- 确认应答丢失

<div align=center><img src=Pictures/超时重传.png></div>

**超时时间应该设置为多少呢？**

先来了解一下什么是**RTT（Round-Trip Time 往返时延）**，从下图我们就可以知道：

<div align=center><img src=Pictures/RTT.png width=50%></div>


RTT就是数据从网络一端传送到另一端所需的时间，也就是包的往返时间。

超时重传时间是以**RTO**（**Retransmission Timeout 超时重传时间**）表示。

**假设在重传的情况下，超时时间RTO「较长或较短」时，会发生什么事情呢？**

<div align=center><img src=Pictures/超时重传1.png></div>

上图中有两种超时时间不同的情况：
- 当超时时间RTO较大时，重发就慢，丢了老半天才重发，没有效率，性能差；
- 当超时时间RTO较小时，会导致可能并没有丢就重发，于是重发的就快，会增加网络拥塞，导致更多的超时，更多的超时导致更多的重发。
- 
精确的测量超时时间RTO的值是非常重要的，这可让我们的重传机制更高效。

根据上述的两种情况，我们可以得知，**超时重传时间RTO的值应该略大于报文往返RTT的值**。

<div align=center><img src=Pictures/超时重传2.png width=50%></div>

至此，可能大家觉得超时重传时间RTO的值计算，也不是很复杂嘛。好像就是在发送端发包时记下t0，然后接收端再把这个ack回来时再记一个t1，于是RTT = t1 – t0。

没那么简单，这只是一个采样，不能代表普遍情况。

实际上「报文往返RTT的值」是经常变化的，因为我们的网络也是时常变化的。也就因为「报文往返 RTT 的值」是经常波动变化的，所以「超时重传时间 RTO 的值」应该是一个**动态变化的值**。

**如果超时重发的数据，再次超时的时候，又需要重传的时候，TCP的策略是超时间隔加倍**。

也就是**每当遇到一次超时重传的时候，都会将下一次超时时间间隔设为先前值的两倍**。两次超时，就说明网络环境差，不宜频繁反复发送。

超时触发重传存在的问题是，**超时周期可能相对较长**。那是不是可以有更快的方式呢？

于是就可以用「快速重传」机制来解决超时重发的时间等待。

##### 快速重传

TCP还有另外一种**快速重传（Fast Retransmit）机制**，它不以时间为驱动，而是**以数据驱动重传**。

快速重传机制，是如何工作的呢？

<div align=center><img src=Pictures/快速重传.png width=70%></div>

在上图，发送方发出了1，2，3，4，5 份数据：
- 第一份Seq1先送到了，于是就Ack回2；
- 结果Seq2因为某些原因没收到，Seq3到达了，于是还是Ack回2；
- 后面的Seq4和Seq5都到了，但还是Ack回2，因为Seq2还是没有收到；
- 发送端收到了三个Ack = 2的确认，知道了Seq2还没有收到，就会在定时器过期之前，重传丢失的 Seq2。
- 最后，收到了Seq2，**此时因为Seq3，Seq4，Seq5都收到了，于是Ack回6**。


所以，快速重传的工作方式是**当收到三个相同的ACK报文时，会在定时器过期之前，重传丢失的报文段**。

快速重传机制只解决了一个问题，就是**超时时间**的问题，但是它依然面临着另外一个问题。就是**重传的时候，是重传之前的一个，还是重传所有**的问题。

比如对于上面的例子，是重传Seq2呢？还是重传Seq2、Seq3、Seq4、Seq5呢？因为发送端并不清楚这连续的三个Ack 2是谁传回来的。

根据TCP不同的实现，以上两种情况都是有可能的。可见，这是一把双刃剑。

为了解决不知道该重传哪些TCP报文，于是就有SACK方法。

##### SACK方法

还有一种实现重传机制的方式叫：**SACK（ Selective Acknowledgment 选择性确认）**。

这种方式需要在TCP头部「选项」字段里加一个SACK，它可以将缓存的地图发送给发送方，这样发送方就可以知道哪些数据收到了，哪些数据没收到，知道了这些信息，就可以只重传丢失的数据。

如下图，发送方收到了三次同样的ACK确认报文，于是就会触发快速重发机制，通过SACK信息发现只有 200~299这段数据丢失，则重发时，就只选择了这个TCP段进行重复。

<div align=center><img src=Pictures/SACK.png></div>

如果要支持SACK，必须双方都要支持。

##### Duplicate SACK
Duplicate SACK又称D-SACK，其主要使用了SACK来告诉「发送方」有**哪些数据被重复接收了**。

下面举例来说明D-SACK的作用：

**ACK丢包：**

<div align=center><img src=Pictures/DSACK.png width=80%></div>

- 「接收方」发给「发送方」的两个 ACK 确认应答都丢失了，所以发送方超时后，重传第一个数据包（3000 ~ 3499）
- 于是「接收方」发现数据是重复收到的，于是回了一个SACK = 3000~3500，告诉「发送方」 3000~3500的数据早已被接收了，因为ACK都到了4000了，已经意味着4000之前的所有数据都已收到，所以这个SACK就代表着D-SACK。
- 这样「发送方」就知道了，数据没有丢，是「接收方」的ACK确认报文丢了。


**网络延时：**

<div align=center><img src=Pictures/DSACK1.png width=80%></div>

- 数据包（1000~1499）被网络延迟了，导致「发送方」没有收到Ack 1500的确认报文。
- 而后面报文到达的三个相同的ACK确认报文，就**触发了快速重传机制**，但是在重传后，被延迟的数据包（1000~1499）又到了「接收方」；
- 所以「接收方」回了一个SACK=1000~1500，因为ACK已经到了3000，所以这个SACK是D-SACK，表示收到了重复的包。
- 这样发送方就知道快速重传触发的原因不是发出去的包丢了，也不是因为回应的ACK包丢了，而是因为网络延迟了。

可见，D-SACK 有这么几个好处： 
1. 可以让「发送方」知道，是发出去的包丢了，还是接收方回应的ACK包丢了; 
2. 可以知道是不是「发送方」的数据包被网络延迟了; 
3. 可以知道网络中是不是把「发送方」的数据包给复制了。

##### 自动重传请求协议ARQ


即`Auto Repeat reQuest`，具体介绍如下：

<div align=center><img src=Pictures/自动重传协议.jpg></div>

<div align=center><img src=Pictures/ARQ类型.webp></div>


**类型1：停等式ARQ(Stop-and-Wait)**

原理：(单帧滑动窗口)停止-等待协议 + 超时重传。即，发送窗口大小=1、接收窗口大小=1。

停止-等待协议的协议原理如下：

- 发送方每发送一帧，要等到接收方的应答信号后才能发送下一帧
- 接收方每接收一帧，都要反馈一个应答信号，表示可接下一帧
- 若接收方不反馈应答信号，则发送方必须一直等待


**类型2：后退N帧协议**

也称：连续ARQ协议

原理：多帧滑动窗口 + 累计确认 + 后退N帧 + 超时重传。即，发送窗口大小>1、接收窗口大小=1

具体描述
- 发送方：采用多帧滑动窗口的原理，可连续发送多个数据帧，而不需等待对方确认
- 接收方：采用**累计确认**和**后退N帧**的原理，只允许按顺序接收帧。具体原理如下：

<div align=center><img src=Pictures/自动重传协议1.jpg></div>

源站向目的站发送数据帧：

<div align=center><img src=Pictures/自动重传协议2.jpg></div>


**类型3：选择重传ARQ(Selective Repeat)**

原理：多帧滑动窗口 + 累计确认 + 后退N帧 + 超时重传。即，发送窗口大小>1、接收窗口大小>1

类似于类型2(后退N帧协议)，此处仅仅是**接收窗口大小的区别**，故此处不作过多描述。

特点：
- 优：因连续发送数据帧而提高了信道的利用率
- 缺：重传时又必须把原来已经传送正确的数据帧进行重传（仅因为这些数据帧前面有一个数据帧出了错），将导致传送效率降低

由此可见，若信道传输质量很差，导致误码率较大时，后退N帧协议不一定优于停止-等待协议。





#### 流量控制

发送方不能无脑的发数据给接收方，要考虑接收方处理能力。如果一直无脑的发数据给对方，但对方处理不过来，那么就会导致触发重发机制，从而导致网络流量的无端的浪费。

为了解决这种现象发生，TCP提供一种机制可以**让「发送方」根据「接收方」的实际接收能力控制发送的数据量**，这就是所谓的流量控制。

为了简单起见，假设以下场景：
- 客户端是接收方，服务端是发送方
- 假设接收窗口和发送窗口相同，都为200 
- 假设两个设备在整个传输过程中都保持相同的窗口大小，不受外界影响

这里要说明下，本例是把服务端作为发送方，所以没有画出服务端的接收窗口。

<div align=center><img src=Pictures/流量控制3.png></div>

根据上图的流量控制，说明下每个过程： 
1. 客户端向服务端发送请求数据报文。 
2. 服务端收到请求报文后，发送确认报文和80字节的数据，于是可用窗口Usable减少为120字节，同时SND.NXT指针也向右偏移80字节后，指向321，这意味着下次发送数据的时候，序列号是321。 
3. 客户端收到80字节数据后，于是接收窗口往右移动80字节，RCV.NXT也就指向321，这意味着客户端期望的下一个报文的序列号是321，接着发送确认报文给服务端。 
4. 服务端再次发送了120字节数据，于是可用窗口耗尽为0，服务端无法再继续发送数据。 
5. 客户端收到120字节的数据后，于是接收窗口往右移动120字节，RCV.NXT也就指向441，接着发送确认报文给服务端。
6. 服务端收到对80字节数据的确认报文后，SND.UNA指针往右偏移后指向321，于是可用窗口Usable 增大到80。
7. 服务端收到对120字节数据的确认报文后，SND.UNA指针往右偏移后指向441，于是可用窗口Usable增大到200。
8. 服务端可以继续发送了，于是发送了160字节的数据后，SND.NXT指向601，于是可用窗口Usable减少到40。
9. 客户端收到160字节后，接收窗口往右移动了160字节，RCV.NXT也就是指向了601，接着发送确认报文给服务端。 
10. 服务端收到对160字节数据的确认报文后，发送窗口往右移动了160字节，于是SND.UNA指针偏移了160后指向601，可用窗口Usable也就增大至了200。



<div align=center><img src=Pictures/流量控制.jpg width=80%></div>

<div align=center><img src=Pictures/流量控制2.webp></div>

**死锁问题：**

<div align=center><img src=Pictures/流量控制2.jpg></div>


#### 拥塞控制

**流量控制是避免「发送方」的数据填满「接收方」的缓存**，但是并不知道网络的中发生了什么。

一般来说，计算机网络都处在一个共享的环境。因此也有可能会**因为其他主机之间的通信使得网络拥堵**。在网络出现拥堵时，如果继续发送大量数据包，可能会导致数据包时延、丢失等，这时TCP就会重传数据，但是一重传就会导致网络的负担更重，于是会导致更大的延迟以及更多的丢包，这个情况就会进入恶性循环被不断地放大。

所以，**TCP不能忽略网络上发生的事，它被设计成一个无私的协议，当网络发送拥塞时，TCP会自我牺牲，降低发送的数据量**。于是，就有了拥塞控制，控制的目的就是**避免「发送方」的数据填满整个网络**。

**防止过多的数据注入到网络中**，使得网络中的路由器和链路不致于过载。

拥塞：对网络中的资源需求 > 该资源所能提供的部分。网络中的链路容量和交换结点中的缓存和处理机都有着工作的极限，**当网络的需求超过它们的工作极限时，就出现了拥塞**。

与 “流量控制”的区别：

<div align=center><img src=Pictures/拥塞控制.webp></div>

具体解决方案，共分为2个解决方案：**慢开始与拥塞避免**、**快重传与快恢复**。



##### 拥塞窗口

发送方维持一个状态变量：拥塞窗口(cwnd, congestion window)

<div align=center><img src=Pictures/拥塞控制2.jpg width=80%></div>

拥塞窗口cwnd是发送方维护的一个的状态变量，它会根据网络的拥塞程度动态变化的。发送窗口swnd 和接收窗口rwnd是约等于的关系，那么由于加入了拥塞窗口的概念后，此时发送窗口的值是`swnd = min(cwnd, rwnd)`，也就是拥塞窗口和接收窗口中的最小值。

拥塞窗口cwnd变化的规则：
- 只要网络中没有出现拥塞，cwnd就会增大；
- 但网络中出现了拥塞，cwnd就减少；
- 
**那么怎么知道当前网络是否出现了拥塞呢？**

其实只要**「发送方」没有在规定时间内接收到ACK应答报文**，也就是发生了超时重传，就会认为网络出现了用拥塞。

##### 慢开始

TCP在刚建立连接完成后，首先是有个慢启动的过程，这个慢启动的意思就是**一点一点的提高发送数据包的数量**，如果一上来就发大量的数据，这不是给网络添堵嘛！

慢启动的算法记住一个规则就行：**当发送方每收到一个ACK，拥塞窗口cwnd的大小就会加1**。

这里假定拥塞窗口cwnd和发送窗口swnd相等，举例：

- 连接建立完成后，一开始初始化cwnd = 1，表示可以传一个MSS大小的数据。
- 当收到一个ACK确认应答后，cwnd增加1，于是一次能够发送2个 
- 当收到2个ACK确认应答后，cwnd增加 2，于是就可以比之前多发2个，所以这一次能够发送4个
- 当这4个的ACK确认到来的时候，每个确认cwnd增加1，4个确认cwnd增加4，于是就可以比之前多发4个，所以这一次能够发送8个。

<div align=center><img src=Pictures/慢开始.png></div>

可以看出慢启动算法，发包的个数是**指数性的增长**。

**那慢启动涨到什么时候是个头呢？**

有一个叫**慢启动门限ssthresh （slow start threshold）状态变量**：
- 当`cwnd < ssthresh`时，使用慢启动算法。
- 当`cwnd >= ssthresh`时，就会使用「拥塞避免算法」。

**原理**：当主机开始发送数据时，由小到大逐渐增大拥塞窗口数值（即发送窗口数值），从而由小到大逐渐增大发送报文段。

**目的**：**开始传输时，试探网络的拥塞情况**

**具体措施**

<div align=center><img src=Pictures/拥塞控制3.webp></div>

<div align=center><img src=Pictures/拥塞控制4.webp></div>

慢开始的“慢”指：**一开始发送报文段时拥塞窗口(cwnd)设置得较小(为1)**，使得发送方在开始时只发送一个报文段（目的是试探一下网络的拥塞情况）。并不是指拥塞窗口(cwnd)的增长速率慢。


##### 拥塞避免

当拥塞窗口cwnd「超过」慢启动门限ssthresh就会进入拥塞避免算法。一般来说ssthresh的大小是65535字节。

那么进入拥塞避免算法后，它的规则是：**每当收到一个ACK时，cwnd增加1/cwnd**。

接上前面的慢启动的例子，现假定ssthresh为8：

当8个ACK应答确认到来时，每个确认增加1/8，8个ACK确认cwnd一共增加1，于是这一次能够发送9个MSS大小的数据，变成了**线性增长**：

<div align=center><img src=Pictures/拥塞避免.png width=80%></div>

拥塞避免算法就是**将原本慢启动算法的指数增长变成了线性增长**，还是增长阶段，但是增长速度缓慢了一些。

就这么一直增长着后，网络就会慢慢进入了拥塞的状况了，于是就会出现**丢包现象**，这时就需要对丢失的数据包进行重传。当触发了重传机制，也就进入了「拥塞发生算法」。

- 拥塞避免算法

  - 原理：**使得拥塞窗口(cwnd)按线性规律缓慢增长**：每经过一个往返时间RTT，发送方的拥塞窗口(cwnd)加1。

  - 拥塞避免并不可避免拥塞，只是将拥塞窗口按现行规律缓慢增长，使得网络比较不容易出现拥塞

  - 相比慢开始算法的加倍，拥塞窗口增长速率缓慢得多


<div align=center><img src=Pictures/拥塞避免.webp></div>

- 方案描述

**为了防止拥塞窗口(cwnd)增长过大而引起网络拥塞，采用慢开始与拥塞避免**，具体规则如下：

<div align=center><img src=Pictures/拥塞控制5.jpg></div>

- 示例

<div align=center><img src=Pictures/拥塞控制6.webp></div>


##### 快速重传和快速恢复

当网络出现拥塞，也就是会发生**数据包重传**，重传机制主要有两种：
- 超时重传
- 快速重传

这两种使用的拥塞发送算法是不同的。

发生**超时重传的拥塞发生算法**：

当发生了「超时重传」，则就会使用拥塞发生算法。这个时候，ssthresh和cwnd的值会发生变化：
- ssthresh设为cwnd/2，
- cwnd重置为1

<div align=center><img src=Pictures/拥塞发生超时重传.png></div>

接着，就**重新开始慢启动**，**慢启动时会突然减少数据流的**。但是这种方式太激进了，反应也很强烈，会造成网络卡顿。

还有更好的方式——**快速重传算法**。

当接收方发现丢了一个中间包的时候，发送三次前一个包的ACK，于是发送端就会快速地重传，不必等待超时再重传。

TCP认为这种情况不严重，因为大部分没丢，只丢了一小部分，则ssthresh和cwnd变化如下：
- cwnd = cwnd/2 ，也就是设置为原来的一半;
- ssthresh = cwnd;
- 进入快速恢复算法

快重传与快恢复的解决方案是对慢开始与拥塞避免算法的改进。

- 快重传算法

  - 原理

    - **接收方每收到一个失序的报文段后就立即发出重复确认**（为的是使发送方及早知道有报文段没有到达对方），而不要等到自己发送数据时才进行捎带确认
    - 发送方只要一连收到3个重复确认就立即重传对方尚未收到的报文段，而不必 继续等待设置的重传计时器到期
  
  - 作用：由于**发送方尽早重传未被确认的报文段**，因此采用快重传后可以使整个网络吞吐量提高约20%

<div align=center><img src=Pictures/快重传.webp></div>




- 快恢复

  当发送方连续收到3个重复确认后，就：

    - 执行乘法减小算法：把慢开始门限(ssthresh)设置为出现拥塞时发送方窗口值的一半 = 拥塞窗口的1半
    - 将拥塞窗口(cwnd)值设置为慢开始门限ssthresh减半后的数值 = 拥塞窗口的1半
    - 执行加法增大算法：执行拥塞避免算法，使拥塞窗口缓慢地线性增大。

- 方案描述

  为了优化慢开始与拥塞避免的解决方案，在上述方案中加入快重传与快恢复算法，具体规则如下：


<div align=center><img src=Pictures/快重传快恢复.jpg></div>

快速重传和快速恢复算法一般同时使用，快速恢复算法是认为，你还能收到3个重复ACK说明网络也不那么糟糕，所以没有必要像RTO超时那么强烈。

进入快速恢复之前，cwnd和ssthresh已被更新了：
- cwnd = cwnd/2 ，也就是设置为原来的一半;
- ssthresh = cwnd
  

然后，进入快速恢复算法如下：

- 拥塞窗口cwnd = ssthresh + 3（3的意思是确认有3个数据包被收到了）；
- 重传丢失的数据包；
- 如果再收到重复的ACK，那么cwnd增加1；
- 如果收到新数据的ACK后，把cwnd设置为第一步中的ssthresh的值，原因是该ACK确认了新的数据，说明从duplicated ACK时的数据都已收到，该恢复过程已经结束，可以回到恢复之前的状态了，也即再次进入拥塞避免状态
  
<div align=center><img src=Pictures/快速重传和快速恢复.png></div>

也就是没有像「超时重传」一夜回到解放前，而是还在比较高的值，后续呈线性增长。

**拥塞算法示意图：**

<div align=center><img src=Pictures/拥塞控制7.webp></div>

<div align=center><img src=Pictures/拥塞控制8.jpg></div>










